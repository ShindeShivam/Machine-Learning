{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13248595,"sourceType":"datasetVersion","datasetId":8394833},{"sourceId":13255611,"sourceType":"datasetVersion","datasetId":8399703}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport json","metadata":{"id":"YjBNqJTRCgQO","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:48.792069Z","iopub.execute_input":"2025-10-05T02:46:48.792911Z","iopub.status.idle":"2025-10-05T02:46:52.666611Z","shell.execute_reply.started":"2025-10-05T02:46:48.792237Z","shell.execute_reply":"2025-10-05T02:46:52.666074Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if torch.cuda.is_available():\n  device = 'cuda'\n  print(torch.cuda.device_count())\nelif torch.backends.mps.is_available():\n  device = 'mps'\nelse:\n  device = 'cpu'\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bqYkafYCndQ","outputId":"3bf45a10-9a57-4e67-be1f-6695fb35623d","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:52.667898Z","iopub.execute_input":"2025-10-05T02:46:52.668327Z","iopub.status.idle":"2025-10-05T02:46:52.776460Z","shell.execute_reply.started":"2025-10-05T02:46:52.668308Z","shell.execute_reply":"2025-10-05T02:46:52.775742Z"}},"outputs":[{"name":"stdout","text":"2\ncuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Transformer Architecture","metadata":{"id":"j7bfqkfGCRSI"}},{"cell_type":"markdown","source":"## Positional encodings","metadata":{"id":"jcFLqG7pCXtc"}},{"cell_type":"code","source":"class PositionalEncodings(nn.Module):\n  def __init__(self, max_len, embed_dim, dropout=0.1):\n    super().__init__()\n    # pos_embed: learnable positional embeddings for all positions up to max_len\n    # Shape = [max_len, embed_dim]\n    # Example: if max_len=500 and embed_dim=512 → [500, 512]\n    self.pos_embed = nn.Parameter(torch.randn(max_len, embed_dim) * 0.02)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, X):\n    \"\"\"\n    X: token embeddings\n    Shape = [batch_size, seq_len, embed_dim]\n\n    self.pos_embed[:X.size(1)]:\n        - X.size(1) = seq_len\n        - So we take the first `seq_len` rows from pos_embed\n        - Shape = [seq_len, embed_dim]\n\n    Broadcasting when adding:\n        - X: [batch_size, seq_len, embed_dim]\n        - pos_embed[:seq_len]: [seq_len, embed_dim]\n        - Automatically broadcast to [1, seq_len, embed_dim] → [batch_size, seq_len, embed_dim]\n\n    Final output:\n        - Shape = [batch_size, seq_len, embed_dim]\n    \"\"\"\n    return self.dropout(X + self.pos_embed[:X.size(1)])\n\n","metadata":{"id":"dYBqTShgAxTQ","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:52.777309Z","iopub.execute_input":"2025-10-05T02:46:52.777572Z","iopub.status.idle":"2025-10-05T02:46:52.782771Z","shell.execute_reply.started":"2025-10-05T02:46:52.777548Z","shell.execute_reply":"2025-10-05T02:46:52.782115Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"max_len = 500\nembed_dim = 512\npos_embedding = PositionalEncodings(max_len, embed_dim)\nembeddings = torch.randn(256, 500, 512)\nembeddings_with_pos = pos_embedding(embeddings)\nembeddings_with_pos.shape\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAVJF2c6DIk-","outputId":"0c26feef-7032-4543-dcb6-50e431005fec","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:52.783350Z","iopub.execute_input":"2025-10-05T02:46:52.783554Z","iopub.status.idle":"2025-10-05T02:46:53.971483Z","shell.execute_reply.started":"2025-10-05T02:46:52.783529Z","shell.execute_reply":"2025-10-05T02:46:53.970737Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"torch.Size([256, 500, 512])"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"a = torch.tensor([1,2,3,4,5])\nb = torch.tensor([6,7,8,9,0])","metadata":{"id":"X4N130rNAJ5b","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:53.973267Z","iopub.execute_input":"2025-10-05T02:46:53.973477Z","iopub.status.idle":"2025-10-05T02:46:53.978314Z","shell.execute_reply.started":"2025-10-05T02:46:53.973461Z","shell.execute_reply":"2025-10-05T02:46:53.977612Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"c = torch.cat((a,b))\nc\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHrK7MIXAJXi","outputId":"1aa0de92-675c-4884-d178-a34a23d5e574","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:53.979031Z","iopub.execute_input":"2025-10-05T02:46:53.979256Z","iopub.status.idle":"2025-10-05T02:46:54.004947Z","shell.execute_reply.started":"2025-10-05T02:46:53.979234Z","shell.execute_reply":"2025-10-05T02:46:54.004268Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Multi-Head Attention","metadata":{"id":"itTAvHn8AnNS"}},{"cell_type":"markdown","source":"### How splitting works","metadata":{"id":"AHcbeGIHNj0n"}},{"cell_type":"code","source":"import torch\n\n# Input embeddings: (B, L, E) = (1, 3, 6)\nx = torch.tensor([[[1, 2, 3, 4, 5, 6],    # token 1 embedding\n                   [7, 8, 9, 10, 11, 12],   # token 2 embedding\n                   [13, 14, 15, 16, 17, 18]]])   # token 3 embedding\nprint(\"Input embeddings x:\", x)\nprint(\"Shape:\", x.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33oL-kQfD_ZL","outputId":"631f1c58-6a93-4c3a-a889-0a9c03d33f47","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.005889Z","iopub.execute_input":"2025-10-05T02:46:54.006086Z","iopub.status.idle":"2025-10-05T02:46:54.011781Z","shell.execute_reply.started":"2025-10-05T02:46:54.006071Z","shell.execute_reply":"2025-10-05T02:46:54.011091Z"}},"outputs":[{"name":"stdout","text":"Input embeddings x: tensor([[[ 1,  2,  3,  4,  5,  6],\n         [ 7,  8,  9, 10, 11, 12],\n         [13, 14, 15, 16, 17, 18]]])\nShape: torch.Size([1, 3, 6])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"B, L, E = x.shape\nH = 2\nD = E // H\nx_heads = x.view(B, L, H, D)  # (B, L, H, D)\nprint(x_heads.shape)\nx_heads","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XR85bL5aL_I9","outputId":"2456b442-638e-476d-8b31-2692c796478a","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.012451Z","iopub.execute_input":"2025-10-05T02:46:54.012688Z","iopub.status.idle":"2025-10-05T02:46:54.024317Z","shell.execute_reply.started":"2025-10-05T02:46:54.012665Z","shell.execute_reply":"2025-10-05T02:46:54.023715Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 2, 3])\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[[[ 1,  2,  3],\n          [ 4,  5,  6]],\n\n         [[ 7,  8,  9],\n          [10, 11, 12]],\n\n         [[13, 14, 15],\n          [16, 17, 18]]]])"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"X = x_heads.transpose(1,2)  # (B, H, L, D)\nprint(X.shape)\nx_heads","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UHfx8pdMN2J","outputId":"4ad66dca-6d17-41c6-f12a-ba6a32eaae0c","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.024895Z","iopub.execute_input":"2025-10-05T02:46:54.025095Z","iopub.status.idle":"2025-10-05T02:46:54.035147Z","shell.execute_reply.started":"2025-10-05T02:46:54.025077Z","shell.execute_reply":"2025-10-05T02:46:54.034448Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 2, 3, 3])\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([[[[ 1,  2,  3],\n          [ 4,  5,  6]],\n\n         [[ 7,  8,  9],\n          [10, 11, 12]],\n\n         [[13, 14, 15],\n          [16, 17, 18]]]])"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### Custom MHA","metadata":{"id":"5GZckFVTSMd1"}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n  def __init__(self, embed_dim, num_heads, dropout=0.1):\n    super().__init__()\n    self.H = num_heads\n    self.D = embed_dim // num_heads\n    self.q_proj = nn.Linear(embed_dim, embed_dim)\n    self.k_proj = nn.Linear(embed_dim, embed_dim)\n    self.v_proj = nn.Linear(embed_dim, embed_dim)\n    self.out_proj = nn.Linear(embed_dim, embed_dim)\n    self.dropout = nn.Dropout(dropout)\n\n  def split_heads(self, X):\n    return X.view(X.size(0), X.size(1), self.H, self.D).transpose(1, 2)\n\n  def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n    q = self.split_heads(self.q_proj(query)) # (B, H, Lq, D)\n    k = self.split_heads(self.k_proj(key))  # (B, H, Lk, D)\n    v = self.split_heads(self.v_proj(value)) # (B, H, Lv, D) with Lv=Lk\n    scores = q @ k.transpose(2, 3) / self.D**0.5   # (B, H, Lq, Lk)\n\n    if attn_mask is not None:\n      scores = scores.masked_fill(attn_mask, -torch.inf)  # (B, H, Lq, Lk)\n    if key_padding_mask is not None:\n      mask = key_padding_mask.unsqueeze(1).unsqueeze(2) # (B, 1, 1, Lk)\n      scores = scores.masked_fill(mask, -torch.inf)  # (B, H, Lq, Lk)\n\n    weights = scores.softmax(dim=-1) # (B, H, Lq, Lk)\n    Z = self.dropout(weights) @ v # (B, H, Lq, D)\n    Z = Z.transpose(1, 2)\n    Z = Z.reshape(Z.size(0), Z.size(1), self.H * self.D)\n    return (self.out_proj(Z), weights)\n","metadata":{"id":"28ndz1RlNr9U","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.035896Z","iopub.execute_input":"2025-10-05T02:46:54.036150Z","iopub.status.idle":"2025-10-05T02:46:54.048911Z","shell.execute_reply.started":"2025-10-05T02:46:54.036128Z","shell.execute_reply":"2025-10-05T02:46:54.048339Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Transformer Encoder Layer","metadata":{"id":"bqH0fx-QeZ1W"}},{"cell_type":"code","source":"class TransformerEncoderLayer(nn.Module):\n  def __init__(self, dim_model, n_heads, dim_ff=2048, dropout=0.1):\n    super().__init__()\n    self.self_attn = MultiHeadAttention(dim_model, n_heads, dropout)\n    self.linear1 = nn.Linear(dim_model, dim_ff)\n    self.linear2 = nn.Linear(dim_ff, dim_model)\n    self.dropout = nn.Dropout(dropout)\n    self.norm1 = nn.LayerNorm(dim_model)\n    self.norm2 = nn.LayerNorm(dim_model)\n\n  def forward(self, src, src_mask=None, src_key_padding_mask=None):\n    attn, _ = self.self_attn(src, src, src, src_mask, src_key_padding_mask)\n    Z = self.norm1(src + self.dropout(attn))\n    ff = self.dropout(self.linear2(self.dropout(self.linear1(Z).relu())))\n\n    return self.norm2(Z + ff)\n\n","metadata":{"id":"keTxTYYyeczb","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.049776Z","iopub.execute_input":"2025-10-05T02:46:54.050045Z","iopub.status.idle":"2025-10-05T02:46:54.060811Z","shell.execute_reply.started":"2025-10-05T02:46:54.050023Z","shell.execute_reply":"2025-10-05T02:46:54.060191Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Transformer Decoder Layer","metadata":{"id":"Lm2Iwrv8go3m"}},{"cell_type":"code","source":"class TransformerDecoderLayer(nn.Module):\n  def __init__(self, dim_model, n_heads, dim_ff=2048, dropout=0.1):\n    super().__init__()\n    self.self_attn = MultiHeadAttention(dim_model, n_heads, dropout)\n    self.multi_attn = MultiHeadAttention(dim_model, n_heads, dropout)\n    self.linear1 = nn.Linear(dim_model, dim_ff)\n    self.linear2 = nn.Linear(dim_ff, dim_model)\n    self.norm1 = nn.LayerNorm(dim_model)\n    self.norm2 = nn.LayerNorm(dim_model)\n    self.norm3 = nn.LayerNorm(dim_model)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n              tgt_key_padding_mask=None, memory_key_padding_mask=None):\n    attn1, _ = self.self_attn(tgt, tgt, tgt,\n                              attn_mask=tgt_mask,\n                              key_padding_mask=tgt_key_padding_mask)\n    Z = self.norm1(tgt + self.dropout(attn1))\n    attn2, _ = self.multi_attn(Z, memory, memory,\n                               attn_mask=memory_mask,\n                               key_padding_mask=memory_key_padding_mask)\n    Z = self.norm2(Z + self.dropout(attn2))\n    ff = self.dropout(self.linear2(self.dropout(self.linear1(Z).relu())))\n    return self.norm3(Z + ff)","metadata":{"id":"kkuFQcCdgrQl","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.061462Z","iopub.execute_input":"2025-10-05T02:46:54.061619Z","iopub.status.idle":"2025-10-05T02:46:54.077247Z","shell.execute_reply.started":"2025-10-05T02:46:54.061605Z","shell.execute_reply":"2025-10-05T02:46:54.076645Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Transformer Encoder","metadata":{"id":"NpfiGPRHoReW"}},{"cell_type":"code","source":"from copy import deepcopy\n\nclass TransformerEncoder(nn.Module):\n  def __init__(self, encoder_layer, num_layers, norm=None):\n    super().__init__()\n    self.layers = nn.ModuleList([deepcopy(encoder_layer)\n                                   for _ in range(num_layers)])\n    self.norm = norm\n\n  def forward(self, src, src_mask=None, src_key_padding_mask=None):\n    Z = src\n    for layer in self.layers:\n      Z = layer(Z, src_mask, src_key_padding_mask)\n\n    if self.norm is not None:\n      Z = self.norm(Z)\n    return Z","metadata":{"id":"3s498sENoLyJ","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.078086Z","iopub.execute_input":"2025-10-05T02:46:54.078322Z","iopub.status.idle":"2025-10-05T02:46:54.088756Z","shell.execute_reply.started":"2025-10-05T02:46:54.078307Z","shell.execute_reply":"2025-10-05T02:46:54.088199Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Transformer Decoder","metadata":{"id":"3TAxBmhup13s"}},{"cell_type":"code","source":"class TransformerDecoder(nn.Module):\n  def __init__(self, decoder_layer, num_layers, norm=None):\n    super().__init__()\n    self.layers = nn.ModuleList([deepcopy(decoder_layer)\n                                  for _ in range(num_layers)])\n    self.norm = norm\n\n  def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n                    tgt_key_padding_mask=None, memory_key_padding_mask=None):\n    Z = tgt\n    for layer in self.layers:\n      Z = layer(Z, memory, tgt_mask, memory_mask,\n                tgt_key_padding_mask, memory_key_padding_mask)\n\n    if self.norm is not None:\n      Z = self.norm(Z)\n    return Z\n","metadata":{"id":"vSnaMDZAp4JB","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.091687Z","iopub.execute_input":"2025-10-05T02:46:54.091956Z","iopub.status.idle":"2025-10-05T02:46:54.101879Z","shell.execute_reply.started":"2025-10-05T02:46:54.091934Z","shell.execute_reply":"2025-10-05T02:46:54.101253Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Transformer","metadata":{"id":"NRJ8nduVrQ2Q"}},{"cell_type":"code","source":"class Transformer(nn.Module):\n  def __init__(self, d_model=512, n_heads=8, n_encoder_layers=6, n_decoder_layers=6,\n               dim_ff = 2048, dropout=0.1):\n    super().__init__()\n\n    encoder_layer = TransformerEncoderLayer(d_model, n_heads, dim_ff, dropout)\n    norm1 = nn.LayerNorm(d_model)\n\n    self.encoder = TransformerEncoder(encoder_layer, n_encoder_layers, norm1)\n\n    decoder_layer = TransformerDecoderLayer(d_model, n_heads, dim_ff, dropout)\n    norm2 = nn.LayerNorm(d_model)\n\n    self.decoder = TransformerDecoder(decoder_layer, n_decoder_layers, norm2)\n\n\n  def forward(self, src, tgt, src_mask=None, tgt_mask=None, memory_mask=None ,\n                src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n    memory = self.encoder(src, src_mask, src_key_padding_mask)\n    output = self.decoder(tgt, memory, tgt_mask, memory_mask,\n                          tgt_key_padding_mask, memory_key_padding_mask)\n\n    return output\n","metadata":{"id":"LxCo_g8rrQLc","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.102574Z","iopub.execute_input":"2025-10-05T02:46:54.102799Z","iopub.status.idle":"2025-10-05T02:46:54.112960Z","shell.execute_reply.started":"2025-10-05T02:46:54.102777Z","shell.execute_reply":"2025-10-05T02:46:54.112387Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Building English-to-Hinglish Transformer","metadata":{"id":"jZGquWj_yztY"}},{"cell_type":"code","source":"class NmtTransformer(nn.Module):\n  def __init__(self, vocab_size, max_length, embed_dim=512, pad_id=0,\n               num_heads=8, num_layers=6,dim_ff = 2048, dropout=0.1):\n    super().__init__()\n    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_id)\n    self.pos_embed = PositionalEncodings(max_length, embed_dim, dropout)\n    self.transformer = Transformer(embed_dim, num_heads, n_encoder_layers=num_layers,\n                                   n_decoder_layers=num_layers,\n                                   dim_ff=dim_ff, dropout=dropout)\n    self.output = nn.Linear(embed_dim, vocab_size)\n\n  def forward(self, pair):\n    src_embeddings = self.pos_embed(self.embed(pair.src_token_ids))\n    tgt_embeddings = self.pos_embed(self.embed(pair.tgt_token_ids))\n    src_pad_mask = ~pair.src_mask.bool()\n    tgt_pad_mask = ~pair.tgt_mask.bool()\n    size = [pair.tgt_token_ids.size(1)] * 2     #line a\n    full_mask = torch.full(size, True, device=tgt_pad_mask.device) #line b\n    causal_mask = torch.triu(full_mask, diagonal=1)  #line c\n    output_decoder = self.transformer(src_embeddings,\n                                      tgt_embeddings,\n                                      tgt_mask=causal_mask,\n                                      src_key_padding_mask=src_pad_mask,\n                                      tgt_key_padding_mask=tgt_pad_mask,\n                                      memory_key_padding_mask=src_pad_mask)\n    return self.output(output_decoder).permute(0, 2, 1)\n","metadata":{"id":"aVAdqcPLyv4c","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.113697Z","iopub.execute_input":"2025-10-05T02:46:54.113937Z","iopub.status.idle":"2025-10-05T02:46:54.127425Z","shell.execute_reply.started":"2025-10-05T02:46:54.113922Z","shell.execute_reply":"2025-10-05T02:46:54.126867Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"**How line a, line b, line c works :**\n\n***Example:***\n\nseq_len = 5\n\nsize = [seq_len] * 2 -> [5, 5]\n\nfull_mask = torch.full(size, True)\n\nfull_mask:\n\ntensor( [\n\n        [ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True]\n\n        ])\n\ncausal_mask = torch.triu(full_mask, diagonal=1)\n\ncausal_mask:\n\ntensor([\n\n        [False,  True,  True,  True,  True],\n        [False, False,  True,  True,  True],\n        [False, False, False,  True,  True],\n        [False, False, False, False,  True],\n        [False, False, False, False, False]\n        \n        ])\n\n","metadata":{"id":"qpCt5kYH7_ua"}},{"cell_type":"markdown","source":"## Data for NMT","metadata":{"id":"ILJ9fBaM1Xu3"}},{"cell_type":"code","source":"\ndata = []\nfilename = \"/kaggle/input/my-dataset/hinglish_upload_v1.json\"\n\nwith open(filename, \"r\", encoding=\"utf-8\") as f:\n  for line in f:\n    obj = json.loads(line)\n    data.append({\n        \"English\":obj[\"translation\"][\"en\"],\n        \"Hinglish\":obj[\"translation\"][\"hi_ng\"]\n    })\n","metadata":{"id":"BEZkS_l01ctK","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.128014Z","iopub.execute_input":"2025-10-05T02:46:54.128213Z","iopub.status.idle":"2025-10-05T02:46:54.886026Z","shell.execute_reply.started":"2025-10-05T02:46:54.128198Z","shell.execute_reply":"2025-10-05T02:46:54.885161Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\ndf = pd.DataFrame(data)\ndf = df.sample(frac=1).reset_index(drop=True)\n\ndef preprocess_text(text):\n  return str(text).strip()\n\nen_sentence = df[\"English\"].apply(preprocess_text).tolist()\nhing_sentence = df[\"Hinglish\"].apply(preprocess_text).tolist()\n\nfor i in range(3):\n    print(en_sentence[i], \"=>\", hing_sentence[i])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-mk4oV91hOF","outputId":"b9b69d1b-bf8e-444a-e58d-3db2a11b96d5","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:54.886783Z","iopub.execute_input":"2025-10-05T02:46:54.887115Z","iopub.status.idle":"2025-10-05T02:46:55.189072Z","shell.execute_reply.started":"2025-10-05T02:46:54.887089Z","shell.execute_reply":"2025-10-05T02:46:55.188349Z"}},"outputs":[{"name":"stdout","text":"Remind me where is my appointment => mujhe yaad dilao ki mera appointment kaha hai\nSet timer for an hour => ek ghante ke liye timer set karen\nAnd when the Garden is brought near; - => And when the Garden nikat kar di jayegi.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import tokenizers\ndef train_eng_hing():\n  for en, hi in zip(en_sentence, hing_sentence):\n    yield en\n    yield hi\nmax_len = 500\nvocab_size = 10_000\n\nnmt_tokenizer_model = tokenizers.models.BPE(unk_token=\"\")\nnmt_tokenizer = tokenizers.Tokenizer(nmt_tokenizer_model)\nnmt_tokenizer.enable_padding(pad_id=0, pad_token=\"\")\nnmt_tokenizer.enable_truncation(max_length=max_len)\nnmt_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Whitespace()\nnmt_tokenizer_trainer = tokenizers.trainers.BpeTrainer(\n    vocab_size=vocab_size, special_tokens=[\"\", \"\", \"\", \"\"])\nnmt_tokenizer.train_from_iterator(train_eng_hing(), nmt_tokenizer_trainer)\n\n","metadata":{"id":"ZwHf9krj1kKH","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:55.189975Z","iopub.execute_input":"2025-10-05T02:46:55.190216Z","iopub.status.idle":"2025-10-05T02:46:57.720897Z","shell.execute_reply.started":"2025-10-05T02:46:55.190199Z","shell.execute_reply":"2025-10-05T02:46:57.720084Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\nnmt_tokenizer.encode(\"I love football\").ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OY-nPzf1luo","outputId":"7184ed5a-f629-4068-c2e9-819a72865b5e","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:57.721686Z","iopub.execute_input":"2025-10-05T02:46:57.721948Z","iopub.status.idle":"2025-10-05T02:46:57.727027Z","shell.execute_reply.started":"2025-10-05T02:46:57.721921Z","shell.execute_reply":"2025-10-05T02:46:57.726402Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[41, 1248, 2274]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"nmt_tokenizer.encode(\"Muje football pasand hai.\").ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enWuUj8S1nbG","outputId":"92f7941c-5faa-406e-9d98-4b6489670d53","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:57.727668Z","iopub.execute_input":"2025-10-05T02:46:57.727984Z","iopub.status.idle":"2025-10-05T02:46:57.739518Z","shell.execute_reply.started":"2025-10-05T02:46:57.727969Z","shell.execute_reply":"2025-10-05T02:46:57.739000Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[755, 2274, 1849, 346, 14]"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from collections import namedtuple\n\nfields = [\"src_token_ids\", \"src_mask\", \"tgt_token_ids\", \"tgt_mask\"]\nclass NMTPair(namedtuple(\"NmtPairBase\", fields)):\n  def to(self,device):\n    return NMTPair(\n        self.src_token_ids.to(device),\n        self.src_mask.to(device),\n        self.tgt_token_ids.to(device),\n        self.tgt_mask.to(device)\n    )\n\n","metadata":{"id":"TWOgmofv1pa7","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:57.740132Z","iopub.execute_input":"2025-10-05T02:46:57.740284Z","iopub.status.idle":"2025-10-05T02:46:57.749499Z","shell.execute_reply.started":"2025-10-05T02:46:57.740272Z","shell.execute_reply":"2025-10-05T02:46:57.748776Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def nmt_collate_fn(batch):\n  src_text = [item[\"English\"] for item in batch]\n  tgt_text = [f\" {item['Hinglish']} \" for item in batch]\n  src_encodings = nmt_tokenizer.encode_batch(src_text)\n  tgt_encodings = nmt_tokenizer.encode_batch(tgt_text)\n  src_token_ids = torch.tensor([enc.ids for enc in src_encodings])\n  tgt_token_ids = torch.tensor([enc.ids for enc in tgt_encodings])\n  src_mask = torch.tensor([enc.attention_mask for enc in src_encodings])\n  tgt_mask = torch.tensor([enc.attention_mask for enc in tgt_encodings])\n  inputs = NMTPair(src_token_ids,\n                  src_mask,\n                  tgt_token_ids[:,:-1],\n                  tgt_mask[:,:-1])\n  labels =tgt_token_ids[:,1:]\n  return inputs, labels","metadata":{"id":"NkUXTPKV1rgk","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:57.750212Z","iopub.execute_input":"2025-10-05T02:46:57.750379Z","iopub.status.idle":"2025-10-05T02:46:57.760159Z","shell.execute_reply.started":"2025-10-05T02:46:57.750358Z","shell.execute_reply":"2025-10-05T02:46:57.759605Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train_set = df.to_dict(\"records\")[:int(0.8 * len(df))]\nvalid_set = df.to_dict(\"records\")[int(0.8 * len(df)):]\ntrain_set[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ce2v3NWx1tYn","outputId":"75e21e6e-b82c-4774-8901-a6ed9393c2be","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:57.761372Z","iopub.execute_input":"2025-10-05T02:46:57.761585Z","iopub.status.idle":"2025-10-05T02:46:58.588836Z","shell.execute_reply.started":"2025-10-05T02:46:57.761568Z","shell.execute_reply":"2025-10-05T02:46:58.588269Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'English': 'Remind me where is my appointment',\n 'Hinglish': 'mujhe yaad dilao ki mera appointment kaha hai'}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 64\ntrain_loader = DataLoader(\n    train_set,\n    batch_size=batch_size,\n    collate_fn=nmt_collate_fn,\n    shuffle=True\n)\nvalid_loader =DataLoader(\n    valid_set,\n    batch_size=batch_size,\n    collate_fn=nmt_collate_fn\n)","metadata":{"id":"KkknleCy1vO2","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:58.589422Z","iopub.execute_input":"2025-10-05T02:46:58.589627Z","iopub.status.idle":"2025-10-05T02:46:58.593866Z","shell.execute_reply.started":"2025-10-05T02:46:58.589604Z","shell.execute_reply":"2025-10-05T02:46:58.593218Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import torchmetrics\n\ndef evaluate_tm(model, data_loader, metric):\n  model.eval()\n  metric.reset()\n  with torch.no_grad():\n    for X_batch, y_batch in data_loader:\n      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n      y_pred = model(X_batch)\n      metric.update(y_pred, y_batch)\n  return metric.compute()\n\ndef train(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs,\n          patience=2, factor=0.5):\n  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n      optimizer, mode='max', patience=patience, factor=factor\n  )\n  history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n  for epoch in range(n_epochs):\n    print(f\"Epoch:{epoch+1}/{n_epochs}\")\n    model.train()\n    metric.reset()\n    total_loss = 0\n    for idx, (X_batch, y_batch) in enumerate(train_loader):\n      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n      y_pred = model(X_batch)\n      loss = criterion(y_pred, y_batch)\n      total_loss += loss.item()\n      loss.backward()\n      optimizer.step()\n      optimizer.zero_grad()\n      metric.update(y_pred, y_batch)\n      print(f\"\\rBatch {idx+1}/{len(train_loader)}\", end=\"\")\n      print(f\", loss ={total_loss/(idx+1 ):.4f} \", end=\"\")\n    mean_loss = total_loss / len(train_loader)\n    history[\"train_losses\"].append(mean_loss)\n    history[\"train_metrics\"].append(metric.compute().item())\n    val_metric = evaluate_tm(model, valid_loader, metric).item()\n    history[\"valid_metrics\"].append(val_metric)\n    scheduler.step(val_metric)\n    print(f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n             f\"Train Metric: {history['train_metrics'][-1]:.4f}%, \"\n             f\"Valid Metric: {history['valid_metrics'][-1]:.4f}%\")\n  print(\"Training Completed!\")\n  return history\n\n","metadata":{"id":"DJX5JrKi4eut","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:46:58.594671Z","iopub.execute_input":"2025-10-05T02:46:58.594873Z","iopub.status.idle":"2025-10-05T02:47:06.869186Z","shell.execute_reply.started":"2025-10-05T02:46:58.594855Z","shell.execute_reply":"2025-10-05T02:47:06.868555Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## Train the Model","metadata":{"id":"QtfvyX7x9Usq"}},{"cell_type":"code","source":"model = NmtTransformer(vocab_size, max_len, embed_dim=128, pad_id=0, num_heads=8, num_layers=4,dim_ff=1024,\n                       dropout=0.1).to(device)\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n\nmodel = torch.compile(model, mode='reduce-overhead')\n\nn_epochs = 20\nxentropy = nn.CrossEntropyLoss(ignore_index=0)\naccuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocab_size).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-2)\n\nhistory = train(model, optimizer, xentropy, accuracy, train_loader, valid_loader,n_epochs)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"voRgEyrT61Jh","outputId":"e077587a-7b93-4020-985a-21741f118734","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T02:48:13.139509Z","iopub.execute_input":"2025-10-05T02:48:13.140096Z","iopub.status.idle":"2025-10-05T03:48:26.489247Z","shell.execute_reply.started":"2025-10-05T02:48:13.140072Z","shell.execute_reply":"2025-10-05T03:48:26.488551Z"}},"outputs":[{"name":"stdout","text":"Epoch:1/20\nBatch 2364/2364, loss =3.8368 Train Loss: 3.8368, Train Metric: 0.0969%, Valid Metric: 0.1243%\nEpoch:2/20\nBatch 2364/2364, loss =2.6773 Train Loss: 2.6773, Train Metric: 0.1262%, Valid Metric: 0.1381%\nEpoch:3/20\nBatch 2364/2364, loss =2.2644 Train Loss: 2.2644, Train Metric: 0.1363%, Valid Metric: 0.1466%\nEpoch:4/20\nBatch 2364/2364, loss =2.0071 Train Loss: 2.0071, Train Metric: 0.1436%, Valid Metric: 0.1513%\nEpoch:5/20\nBatch 2364/2364, loss =1.8315 Train Loss: 1.8315, Train Metric: 0.1484%, Valid Metric: 0.1554%\nEpoch:6/20\nBatch 2364/2364, loss =1.7063 Train Loss: 1.7063, Train Metric: 0.1532%, Valid Metric: 0.1576%\nEpoch:7/20\nBatch 2364/2364, loss =1.6101 Train Loss: 1.6101, Train Metric: 0.1560%, Valid Metric: 0.1604%\nEpoch:8/20\nBatch 2364/2364, loss =1.5307 Train Loss: 1.5307, Train Metric: 0.1589%, Valid Metric: 0.1626%\nEpoch:9/20\nBatch 2364/2364, loss =1.4640 Train Loss: 1.4640, Train Metric: 0.1613%, Valid Metric: 0.1645%\nEpoch:10/20\nBatch 2364/2364, loss =1.4045 Train Loss: 1.4045, Train Metric: 0.1640%, Valid Metric: 0.1661%\nEpoch:11/20\nBatch 2364/2364, loss =1.3594 Train Loss: 1.3594, Train Metric: 0.1647%, Valid Metric: 0.1677%\nEpoch:12/20\nBatch 2364/2364, loss =1.3156 Train Loss: 1.3156, Train Metric: 0.1666%, Valid Metric: 0.1689%\nEpoch:13/20\nBatch 2364/2364, loss =1.2769 Train Loss: 1.2769, Train Metric: 0.1682%, Valid Metric: 0.1696%\nEpoch:14/20\nBatch 2364/2364, loss =1.2423 Train Loss: 1.2423, Train Metric: 0.1701%, Valid Metric: 0.1706%\nEpoch:15/20\nBatch 2364/2364, loss =1.2116 Train Loss: 1.2116, Train Metric: 0.1710%, Valid Metric: 0.1718%\nEpoch:16/20\nBatch 2364/2364, loss =1.1848 Train Loss: 1.1848, Train Metric: 0.1714%, Valid Metric: 0.1730%\nEpoch:17/20\nBatch 2364/2364, loss =1.1567 Train Loss: 1.1567, Train Metric: 0.1729%, Valid Metric: 0.1733%\nEpoch:18/20\nBatch 2364/2364, loss =1.1324 Train Loss: 1.1324, Train Metric: 0.1740%, Valid Metric: 0.1740%\nEpoch:19/20\nBatch 2364/2364, loss =1.1114 Train Loss: 1.1114, Train Metric: 0.1749%, Valid Metric: 0.1744%\nEpoch:20/20\nBatch 2364/2364, loss =1.0902 Train Loss: 1.0902, Train Metric: 0.1753%, Valid Metric: 0.1750%\nTraining Completed!\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T03:51:44.087968Z","iopub.execute_input":"2025-10-05T03:51:44.088628Z","iopub.status.idle":"2025-10-05T03:51:44.094309Z","shell.execute_reply.started":"2025-10-05T03:51:44.088605Z","shell.execute_reply":"2025-10-05T03:51:44.093585Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"5538576"},"metadata":{}}],"execution_count":30}]}