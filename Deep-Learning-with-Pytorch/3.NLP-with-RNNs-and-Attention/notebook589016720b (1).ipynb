{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Sentiment Analysis on IMDB Dataset","metadata":{"id":"DCbX2rcElyDK"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy","metadata":{"id":"ixitY6GnURSZ","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:21:59.893636Z","iopub.execute_input":"2025-09-19T05:21:59.894304Z","iopub.status.idle":"2025-09-19T05:21:59.897921Z","shell.execute_reply.started":"2025-09-19T05:21:59.894280Z","shell.execute_reply":"2025-09-19T05:21:59.896848Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\n    print(torch.cuda.device_count())\nelif torch.backends.mps.is_available():\n    device = \"mps\"\nelse:\n    device = \"cpu\"\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"ERxr3OLzUW_9","outputId":"60d90748-652a-4524-9c33-0a39de71ec9d","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:21:59.899096Z","iopub.execute_input":"2025-09-19T05:21:59.899304Z","iopub.status.idle":"2025-09-19T05:21:59.915951Z","shell.execute_reply.started":"2025-09-19T05:21:59.899281Z","shell.execute_reply":"2025-09-19T05:21:59.915395Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from datasets import load_dataset\n\nimdb_dataset = load_dataset(\"imdb\")\nsplit = imdb_dataset[\"train\"].train_test_split(train_size = 0.8)\nimdb_train, imdb_valid = split[\"train\"], split[\"test\"]\nimdb_test = imdb_dataset[\"test\"]\nimdb_train[:1]","metadata":{"id":"WWn5z8qAUevR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"68280c61-9931-409a-e44f-c89a80577a1c","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:48:00.641560Z","iopub.execute_input":"2025-09-19T05:48:00.642282Z","iopub.status.idle":"2025-09-19T05:48:03.088253Z","shell.execute_reply.started":"2025-09-19T05:48:00.642257Z","shell.execute_reply":"2025-09-19T05:48:03.087662Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'text': [\"I read James Hawes book. It was pretty neat, not great, but entertaining enough. Without having read the book I wouldn't have had the slightest idea what was going on, and it was still a stretch with that knowledge.<br /><br />Literally every element of this film is abysmal in ways I do not have the capacity to describe. Half digested fish could have made a better film with matchsticks and dayglo lipstick.<br /><br />Never before or since as a film made me feel so angry. The Mattress sequels came closest, but even they never reached such depths of utterly putrid nauseating appallingness that this bilge did.<br /><br />Since wasting 90 minutes of my life witnessing this plague on human kind I am now unable to even look at any book by James Hawes without feeling angry. That is the depth of hatred I have for this piece of sh*t. No, that's unfair. Let me apologise to all fecal matter for comparing you to the otherworldly evil that is Rancid Aluminium.<br /><br />Plain and simply a cancer on the world of cinema.\"],\n 'label': [0]}"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ngpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ngpt_tokenizer.pad_token = gpt_tokenizer.eos_token","metadata":{"id":"ZjMmnq-fh1kN","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.278119Z","iopub.execute_input":"2025-09-19T05:22:02.278386Z","iopub.status.idle":"2025-09-19T05:22:02.663142Z","shell.execute_reply.started":"2025-09-19T05:22:02.278358Z","shell.execute_reply":"2025-09-19T05:22:02.662394Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def collate_fn(batch, tokenizer=gpt_tokenizer):\n  review = [review[\"text\"] for review in batch]\n  labels = [[review[\"label\"]] for review in batch]\n  encodings = tokenizer(\n      review,\n      padding=True,\n      truncation=True,\n      max_length=200,\n      return_tensors=\"pt\")\n  labels = torch.tensor(labels, dtype=torch.float32)\n  return encodings, labels","metadata":{"id":"ELUrHFmKVALo","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.665329Z","iopub.execute_input":"2025-09-19T05:22:02.665579Z","iopub.status.idle":"2025-09-19T05:22:02.670080Z","shell.execute_reply.started":"2025-09-19T05:22:02.665558Z","shell.execute_reply":"2025-09-19T05:22:02.669347Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 256\n\nimdb_train_loader = DataLoader(imdb_train, batch_size=batch_size,\n                               collate_fn=collate_fn, shuffle=True)\nimdb_valid_loader = DataLoader(imdb_valid, batch_size=batch_size,\n                               collate_fn=collate_fn)\nimdb_test_loader = DataLoader(imdb_test, batch_size=batch_size,\n                               collate_fn=collate_fn)","metadata":{"id":"921tEv_eWAb3","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.671238Z","iopub.execute_input":"2025-09-19T05:22:02.671475Z","iopub.status.idle":"2025-09-19T05:22:02.685472Z","shell.execute_reply.started":"2025-09-19T05:22:02.671453Z","shell.execute_reply":"2025-09-19T05:22:02.684889Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nclass SentimentAnalysisPackedSeqModel(nn.Module):\n  def __init__(self, vocab_size, n_layers=2, hidden_size=128, embed_size=128,\n               pad_id=0, dropout=0.2):\n    super().__init__()\n    self.embed = nn.Embedding(vocab_size, embed_size,\n                              padding_idx=pad_id)\n    self.gru = nn.GRU(embed_size, hidden_size, num_layers=n_layers,\n                      batch_first=True, dropout=dropout)\n    self.output = nn.Linear(hidden_size, 1)\n\n  def forward(self,encodings):\n    embeddings = self.embed(encodings[\"input_ids\"])\n    lengths = encodings[\"attention_mask\"].sum(dim=1)\n    packed = pack_padded_sequence(embeddings,\n                                  lengths=lengths.cpu(),\n                                  batch_first=True,\n                                  enforce_sorted=False)\n    _outputs, hidden_states = self.gru(packed)\n    return self.output(hidden_states[-1])\n","metadata":{"id":"Dt5bgkk0c9p0","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.686120Z","iopub.execute_input":"2025-09-19T05:22:02.686344Z","iopub.status.idle":"2025-09-19T05:22:02.699874Z","shell.execute_reply.started":"2025-09-19T05:22:02.686325Z","shell.execute_reply":"2025-09-19T05:22:02.699183Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import torchmetrics\n\ndef evaluate_tm(model, data_loader, metric):\n    model.eval()\n    metric.reset()\n    with torch.no_grad():\n        for X_batch, y_batch in data_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred = model(X_batch)\n            metric.update(y_pred, y_batch)\n    return metric.compute()\n\ndef train(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs, patience=2,\n         factor=0.5,epoch_callback=None):\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode=\"max\", patience=patience, factor=factor\n    )\n    history = {\"train_losses\":[],\"train_metrics\":[],\"valid_metrics\":[]}\n    for epoch in range(n_epochs):\n        total_loss = 0\n        metric.reset()\n        model.train()\n        if epoch_callback is not None:\n            epoch_callback(model,epoch)\n        for idx,( X_batch, y_batch) in enumerate(train_loader):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred = model(X_batch)\n            loss = criterion(y_pred, y_batch)\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            metric.update(y_pred, y_batch)\n            print(f\"\\rBatch {idx+1}/{len(train_loader)}\", end=\"\")\n            print(f\", loss ={total_loss/(idx+1 ):.4f} \", end=\"\")\n        mean_loss = total_loss / len(train_loader)\n        history[\"train_losses\"].append(mean_loss)\n        history[\"train_metrics\"].append(metric.compute().item())\n        val_metric = evaluate_tm(model, valid_loader, metric).item()\n        history[\"valid_metrics\"].append(val_metric)\n        scheduler.step(val_metric)\n        print(f\"Epoch:{epoch+1}/{n_epochs}, \"\n             f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n             f\"Train Metric: {history['train_metrics'][-1]:.4f}%, \"\n             f\"Valid Metric: {history['valid_metrics'][-1]:.4f}%\")\n    return history","metadata":{"id":"PCVfnGMjgNee","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.700672Z","iopub.execute_input":"2025-09-19T05:22:02.700889Z","iopub.status.idle":"2025-09-19T05:22:02.714659Z","shell.execute_reply.started":"2025-09-19T05:22:02.700869Z","shell.execute_reply":"2025-09-19T05:22:02.714102Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"vocab_size = gpt_tokenizer.vocab_size\nvocab_size","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQP_DbcpeL3u","outputId":"41c0471a-332d-4294-ad15-fbc7ebb61fe2","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.715316Z","iopub.execute_input":"2025-09-19T05:22:02.715476Z","iopub.status.idle":"2025-09-19T05:22:02.731371Z","shell.execute_reply.started":"2025-09-19T05:22:02.715463Z","shell.execute_reply":"2025-09-19T05:22:02.730706Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"50257"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"imdb_model = SentimentAnalysisPackedSeqModel(vocab_size).to(device)\n\nn_epochs = 10\nxentropy = nn.BCEWithLogitsLoss() # sigmoid + BinaryCrossEntropy\naccuracy = torchmetrics.Accuracy(task=\"binary\").to(device)\noptimizer = torch.optim.NAdam(imdb_model.parameters())\n\nhistory = train(imdb_model, optimizer, xentropy, accuracy, imdb_train_loader, imdb_valid_loader, n_epochs)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HH1ErsAEfNoB","outputId":"4dd9071f-0403-45ab-ee8e-f508c69ef418","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:22:02.732080Z","iopub.execute_input":"2025-09-19T05:22:02.732327Z","iopub.status.idle":"2025-09-19T05:24:36.553105Z","shell.execute_reply.started":"2025-09-19T05:22:02.732302Z","shell.execute_reply":"2025-09-19T05:24:36.552290Z"}},"outputs":[{"name":"stdout","text":"Batch 79/79, loss =0.6771 Epoch:1/10, Train Loss: 0.6771, Train Metric: 0.5766%, Valid Metric: 0.5050%\nBatch 79/79, loss =0.5687 Epoch:2/10, Train Loss: 0.5687, Train Metric: 0.7049%, Valid Metric: 0.7282%\nBatch 79/79, loss =0.3994 Epoch:3/10, Train Loss: 0.3994, Train Metric: 0.8207%, Valid Metric: 0.8054%\nBatch 79/79, loss =0.2630 Epoch:4/10, Train Loss: 0.2630, Train Metric: 0.8929%, Valid Metric: 0.8346%\nBatch 79/79, loss =0.1792 Epoch:5/10, Train Loss: 0.1792, Train Metric: 0.9341%, Valid Metric: 0.8100%\nBatch 79/79, loss =0.1025 Epoch:6/10, Train Loss: 0.1025, Train Metric: 0.9654%, Valid Metric: 0.7446%\nBatch 79/79, loss =0.0559 Epoch:7/10, Train Loss: 0.0559, Train Metric: 0.9823%, Valid Metric: 0.8176%\nBatch 79/79, loss =0.0186 Epoch:8/10, Train Loss: 0.0186, Train Metric: 0.9958%, Valid Metric: 0.8314%\nBatch 79/79, loss =0.0096 Epoch:9/10, Train Loss: 0.0096, Train Metric: 0.9984%, Valid Metric: 0.8258%\nBatch 79/79, loss =0.0049 Epoch:10/10, Train Loss: 0.0049, Train Metric: 0.9991%, Valid Metric: 0.8314%\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### Using Bidirectional RNN","metadata":{"id":"utdezMn6l-9A"}},{"cell_type":"code","source":"class SentimentAnalysisBidiModel(nn.Module):\n  def __init__(self, vocab_size, n_layers=2, hidden_size=128, embed_size=128,\n               pad_id=0, dropout=0.2):\n    super().__init__()\n    self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=pad_id)\n    self.gru = nn.GRU(embed_size, hidden_size, num_layers=n_layers,\n                      batch_first=True, dropout=dropout, bidirectional=True)\n    self.output = nn.Linear(hidden_size * 2, 1)\n\n  def forward(self, encodings):\n    embeddings = self.embed(encodings[\"input_ids\"])\n    lengths = encodings[\"attention_mask\"].sum(dim=1)\n    packed = pack_padded_sequence(embeddings,\n                                  lengths=lengths.cpu(),\n                                  batch_first=True,\n                                  enforce_sorted=False)\n    _outputs, hidden_states = self.gru(packed)\n\n    forward_state = hidden_states[-2] # (batch, hidden_size)\n    backward_state = hidden_states[-1] # (batch, hidden_size)\n\n    final_state = torch.cat((forward_state, backward_state), dim=1)   # (batch, 2*hidden_size)\n\n    return self.output(final_state)\n","metadata":{"id":"vQBrk-ktl4il","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:24:36.554031Z","iopub.execute_input":"2025-09-19T05:24:36.554288Z","iopub.status.idle":"2025-09-19T05:24:36.561196Z","shell.execute_reply.started":"2025-09-19T05:24:36.554271Z","shell.execute_reply":"2025-09-19T05:24:36.560403Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"imdb_bidi_model = SentimentAnalysisBidiModel(vocab_size).to(device)\n\nn_epochs = 10\nxentropy = nn.BCEWithLogitsLoss()\naccuracy = torchmetrics.Accuracy(task=\"binary\").to(device)\noptimizer = torch.optim.NAdam(imdb_bidi_model.parameters())\n\nhistory = train(imdb_bidi_model, optimizer, xentropy, accuracy, imdb_train_loader, imdb_valid_loader, n_epochs)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKM4kjHxoX7y","outputId":"033f84cb-19dc-4384-a148-ad1083634e80","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:24:36.561938Z","iopub.execute_input":"2025-09-19T05:24:36.562174Z","iopub.status.idle":"2025-09-19T05:27:36.047612Z","shell.execute_reply.started":"2025-09-19T05:24:36.562158Z","shell.execute_reply":"2025-09-19T05:27:36.046836Z"}},"outputs":[{"name":"stdout","text":"Batch 79/79, loss =0.6603 Epoch:1/10, Train Loss: 0.6603, Train Metric: 0.5981%, Valid Metric: 0.6548%\nBatch 79/79, loss =0.5076 Epoch:2/10, Train Loss: 0.5076, Train Metric: 0.7508%, Valid Metric: 0.6630%\nBatch 79/79, loss =0.3487 Epoch:3/10, Train Loss: 0.3487, Train Metric: 0.8497%, Valid Metric: 0.8106%\nBatch 79/79, loss =0.2146 Epoch:4/10, Train Loss: 0.2146, Train Metric: 0.9134%, Valid Metric: 0.8068%\nBatch 79/79, loss =0.1148 Epoch:5/10, Train Loss: 0.1148, Train Metric: 0.9580%, Valid Metric: 0.8214%\nBatch 79/79, loss =0.0418 Epoch:6/10, Train Loss: 0.0418, Train Metric: 0.9882%, Valid Metric: 0.7168%\nBatch 79/79, loss =0.0599 Epoch:7/10, Train Loss: 0.0599, Train Metric: 0.9812%, Valid Metric: 0.8236%\nBatch 79/79, loss =0.0087 Epoch:8/10, Train Loss: 0.0087, Train Metric: 0.9980%, Valid Metric: 0.8174%\nBatch 79/79, loss =0.0034 Epoch:9/10, Train Loss: 0.0034, Train Metric: 0.9995%, Valid Metric: 0.8230%\nBatch 79/79, loss =0.0014 Epoch:10/10, Train Loss: 0.0014, Train Metric: 0.9999%, Valid Metric: 0.8206%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"### Using Pretrained Embeddings and Language Models","metadata":{"id":"s32yX0ryCIL5"}},{"cell_type":"code","source":"import transformers\n\ngpt_model = transformers.AutoModel.from_pretrained(\"gpt2\")\ngpt_model.get_input_embeddings()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyQwbJJRCQLl","outputId":"97eccbe2-39f5-4716-efa0-f99af5148056","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:27:36.048494Z","iopub.execute_input":"2025-09-19T05:27:36.048768Z","iopub.status.idle":"2025-09-19T05:27:36.255570Z","shell.execute_reply.started":"2025-09-19T05:27:36.048748Z","shell.execute_reply":"2025-09-19T05:27:36.254902Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 768)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"\nclass SentimentAnalysisPreEmbed(nn.Module):\n  def __init__(self, pretrained_embed, n_layers=2, hidden_size=128,dropout=0.2):\n    super().__init__()\n    weights = pretrained_embed.weight.data\n    self.embed = nn.Embedding.from_pretrained(weights, freeze=True)\n    embed_size = weights.shape[-1]\n    self.gru = nn.GRU(embed_size, hidden_size, num_layers=n_layers,\n                      batch_first=True, dropout=dropout, bidirectional=True)\n    self.output = nn.Linear(hidden_size * 2, 1)\n  \n  def forward(self, encodings):\n    embeddings = self.embed(encodings[\"input_ids\"])\n    lengths = encodings[\"attention_mask\"].sum(dim=1)\n    packed = pack_padded_sequence(embeddings,\n                                  lengths=lengths.cpu(),\n                                  batch_first=True, \n                                  enforce_sorted=False)\n    _outputs, hidden_states = self.gru(packed)\n    forward_state = hidden_states[-2]\n    backward_state = hidden_states[-1]\n\n    final_state = torch.concat((forward_state, backward_state),dim=1)\n    return self.output(final_state)","metadata":{"id":"czooUGLtFG5M","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:27:36.257584Z","iopub.execute_input":"2025-09-19T05:27:36.258233Z","iopub.status.idle":"2025-09-19T05:27:36.263994Z","shell.execute_reply.started":"2025-09-19T05:27:36.258207Z","shell.execute_reply":"2025-09-19T05:27:36.263392Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"\nimdb_model_gpt_embeds = SentimentAnalysisPreEmbed(gpt_model.get_input_embeddings()).to(device)\n\nn_epochs = 10\nxentropy = nn.BCEWithLogitsLoss()\naccuracy = torchmetrics.Accuracy(task=\"binary\").to(device)\noptimizer = torch.optim.NAdam(imdb_model_gpt_embeds.parameters())\n\nhistory = train(imdb_model_gpt_embeds, optimizer, xentropy, accuracy, \n                imdb_train_loader, imdb_valid_loader, n_epochs)\n","metadata":{"id":"fQIL7rWIDWYt","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:27:36.264661Z","iopub.execute_input":"2025-09-19T05:27:36.264828Z","iopub.status.idle":"2025-09-19T05:30:50.304175Z","shell.execute_reply.started":"2025-09-19T05:27:36.264814Z","shell.execute_reply":"2025-09-19T05:30:50.303364Z"}},"outputs":[{"name":"stdout","text":"Batch 79/79, loss =0.6412 Epoch:1/10, Train Loss: 0.6412, Train Metric: 0.6308%, Valid Metric: 0.7360%\nBatch 79/79, loss =0.4164 Epoch:2/10, Train Loss: 0.4164, Train Metric: 0.8080%, Valid Metric: 0.8640%\nBatch 79/79, loss =0.3150 Epoch:3/10, Train Loss: 0.3150, Train Metric: 0.8628%, Valid Metric: 0.8066%\nBatch 79/79, loss =0.2813 Epoch:4/10, Train Loss: 0.2813, Train Metric: 0.8808%, Valid Metric: 0.8732%\nBatch 79/79, loss =0.2350 Epoch:5/10, Train Loss: 0.2350, Train Metric: 0.9068%, Valid Metric: 0.8242%\nBatch 79/79, loss =0.2037 Epoch:6/10, Train Loss: 0.2037, Train Metric: 0.9187%, Valid Metric: 0.8590%\nBatch 79/79, loss =0.1480 Epoch:7/10, Train Loss: 0.1480, Train Metric: 0.9427%, Valid Metric: 0.8618%\nBatch 79/79, loss =0.0646 Epoch:8/10, Train Loss: 0.0646, Train Metric: 0.9788%, Valid Metric: 0.8572%\nBatch 79/79, loss =0.0298 Epoch:9/10, Train Loss: 0.0298, Train Metric: 0.9920%, Valid Metric: 0.8516%\nBatch 79/79, loss =0.0154 Epoch:10/10, Train Loss: 0.0154, Train Metric: 0.9965%, Valid Metric: 0.8610%\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"class SentimentAnalysisModelGPT(nn.Module):\n    def __init__(self, n_layers=2, hidden_size=128, dropout=0.2):\n        super().__init__()\n        self.gpt = transformers.AutoModel.from_pretrained(\"gpt2\")\n        self.gpt.config.pad_token_id = self.gpt.config.eos_token_id\n        embedding_size = self.gpt.config.hidden_size\n        self.gru = nn.GRU(embedding_size, hidden_size, num_layers=n_layers,\n                         batch_first=True, dropout=dropout)\n        self.output = nn.Linear(hidden_size, 1)\n\n    def forward(self, encodings):\n        contextual_embeddings = self.gpt(**encodings).last_hidden_state\n        lengths = encodings[\"attention_mask\"].sum(dim=1)\n        packed = pack_padded_sequence(contextual_embeddings, \n                                      lengths=lengths.cpu(),\n                                      batch_first=True,\n                                      enforce_sorted=False)\n        _outputs, hidden_states = self.gru(packed)\n        return self.output(hidden_states[-1])\n        ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"ZWU-ml6lIyvI","outputId":"7a7257f8-1d85-4bc5-c260-e0e0e8b76974","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:30:50.305035Z","iopub.execute_input":"2025-09-19T05:30:50.305436Z","iopub.status.idle":"2025-09-19T05:30:50.311177Z","shell.execute_reply.started":"2025-09-19T05:30:50.305415Z","shell.execute_reply":"2025-09-19T05:30:50.310490Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"imdb_model_gpt = SentimentAnalysisModelGPT().to(device)\nfor params in imdb_model_gpt.gpt.parameters():\n    params.requires_grad = False\n\nn_epochs = 4\nxentropy = nn.BCEWithLogitsLoss()\naccuracy = torchmetrics.Accuracy(task=\"binary\").to(device)\noptimizer = torch.optim.NAdam(imdb_model_gpt.parameters())\n\nhistory = train(imdb_model_gpt, optimizer, xentropy, accuracy, \n                imdb_train_loader, imdb_valid_loader, n_epochs)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwj3nVG_FvLm","outputId":"64fdab0f-6168-471b-8559-4d4d77c83409","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:32:48.180674Z","iopub.execute_input":"2025-09-19T05:32:48.180929Z","iopub.status.idle":"2025-09-19T05:44:50.546590Z","shell.execute_reply.started":"2025-09-19T05:32:48.180911Z","shell.execute_reply":"2025-09-19T05:44:50.545900Z"}},"outputs":[{"name":"stdout","text":"Batch 79/79, loss =0.6048 Epoch:1/4, Train Loss: 0.6048, Train Metric: 0.6526%, Valid Metric: 0.7722%\nBatch 79/79, loss =0.4083 Epoch:2/4, Train Loss: 0.4083, Train Metric: 0.8154%, Valid Metric: 0.7566%\nBatch 79/79, loss =0.3428 Epoch:3/4, Train Loss: 0.3428, Train Metric: 0.8496%, Valid Metric: 0.8662%\nBatch 79/79, loss =0.3279 Epoch:4/4, Train Loss: 0.3279, Train Metric: 0.8583%, Valid Metric: 0.8386%\n","output_type":"stream"}],"execution_count":36}]}