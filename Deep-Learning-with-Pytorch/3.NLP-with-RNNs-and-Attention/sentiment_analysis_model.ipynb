{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T03:59:59.002725Z","iopub.execute_input":"2025-09-18T03:59:59.003118Z","iopub.status.idle":"2025-09-18T03:59:59.008421Z","shell.execute_reply.started":"2025-09-18T03:59:59.003079Z","shell.execute_reply":"2025-09-18T03:59:59.007300Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"    \n    print(torch.cuda.device_count())\nelif torch.backends.mps.is_available():\n    device = \"mps\"\nelse:\n    device = \"cpu\"\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:00:01.797775Z","iopub.execute_input":"2025-09-18T04:00:01.798223Z","iopub.status.idle":"2025-09-18T04:00:01.808169Z","shell.execute_reply.started":"2025-09-18T04:00:01.798195Z","shell.execute_reply":"2025-09-18T04:00:01.806045Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from datasets import load_dataset\n\nimdb_dataset = load_dataset(\"imdb\")\nsplit = imdb_dataset[\"train\"].train_test_split(train_size = 0.8)\nimdb_train, imdb_valid = split[\"train\"], split[\"test\"]\nimdb_test = imdb_dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:00:03.607485Z","iopub.execute_input":"2025-09-18T04:00:03.607828Z","iopub.status.idle":"2025-09-18T04:00:08.437222Z","shell.execute_reply.started":"2025-09-18T04:00:03.607803Z","shell.execute_reply":"2025-09-18T04:00:08.435989Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"imdb_train[:1][\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:00:33.728250Z","iopub.execute_input":"2025-09-18T04:00:33.728576Z","iopub.status.idle":"2025-09-18T04:00:33.735924Z","shell.execute_reply.started":"2025-09-18T04:00:33.728552Z","shell.execute_reply":"2025-09-18T04:00:33.734964Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[\"This film has been receiving a lot of play lately during the day on either HBO or Cinemax. The reason is that they are assuming people would be interested in comparing it to the Leonardo DiCaprio/Tom Hanks caper of the same name. The only reason to see it is for the attractive Matt Lattanzi. Yum! Although I must say Matt was more than a little long in the tooth to be playing a high schooler. If he were a woman, they'd have had him playing the MOTHER of a high schooler! (Is is just me, or is his daughter starting to look like Shelley Duvall?) Oh yeah, the plot--who cares? Typical teen highjinx played by adults.\"]"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:00:37.557855Z","iopub.execute_input":"2025-09-18T04:00:37.558286Z","iopub.status.idle":"2025-09-18T04:00:38.408982Z","shell.execute_reply.started":"2025-09-18T04:00:37.558252Z","shell.execute_reply":"2025-09-18T04:00:38.407917Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"word_freq = {}\n\nfor text in imdb_train[\"text\"]:\n    word_with_offset = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n    new_word = [word for word, offset in word_with_offset]\n    for word in new_word:\n        word_freq[word] = word_freq.get(word, 0) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:09:49.437476Z","iopub.execute_input":"2025-09-18T04:09:49.438425Z","iopub.status.idle":"2025-09-18T04:10:11.822961Z","shell.execute_reply.started":"2025-09-18T04:09:49.438388Z","shell.execute_reply":"2025-09-18T04:10:11.821837Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"alphabet = []\nfor word in word_freq.keys():\n    for letter in word:\n        if letter not in alphabet:\n            alphabet.append(letter)\nalphabet.sort()\nprint(alphabet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:08:53.650877Z","iopub.execute_input":"2025-09-18T04:08:53.651861Z","iopub.status.idle":"2025-09-18T04:08:53.947801Z","shell.execute_reply.started":"2025-09-18T04:08:53.651829Z","shell.execute_reply":"2025-09-18T04:08:53.946836Z"}},"outputs":[{"name":"stdout","text":"['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '¡', '¢', '£', '¤', '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '®', '¯', '°', '±', '²', '³', '´', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿', 'Â', 'Ã', 'â', 'ï', 'Ĉ', 'ĉ', 'Đ', 'Ġ', 'Ģ', 'Ĥ', 'ĥ', 'Ħ', 'ħ', 'Ī', 'ī', 'Ĭ', 'į', 'İ', 'ĳ', 'ĵ', 'ķ', 'ĸ', 'Ĺ', 'ĺ', 'Ļ', 'ľ', 'Ŀ', 'ŀ', 'Ł', 'ł', 'Ń']\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"vocab = [\"<|endoftext|>\"] + alphabet.copy()\nprint(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:11:35.051383Z","iopub.execute_input":"2025-09-18T04:11:35.051718Z","iopub.status.idle":"2025-09-18T04:11:35.058245Z","shell.execute_reply.started":"2025-09-18T04:11:35.051694Z","shell.execute_reply":"2025-09-18T04:11:35.056742Z"}},"outputs":[{"name":"stdout","text":"['<|endoftext|>', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '¡', '¢', '£', '¤', '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '®', '¯', '°', '±', '²', '³', '´', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿', 'Â', 'Ã', 'â', 'ï', 'Ĉ', 'ĉ', 'Đ', 'Ġ', 'Ģ', 'Ĥ', 'ĥ', 'Ħ', 'ħ', 'Ī', 'ī', 'Ĭ', 'į', 'İ', 'ĳ', 'ĵ', 'ķ', 'ĸ', 'Ĺ', 'ĺ', 'Ļ', 'ľ', 'Ŀ', 'ŀ', 'Ł', 'ł', 'Ń']\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"splits = {word:[c for c in word] for word in word_freq.keys()}\n\ndef compute_pair_freq(splits):\n    pair_freq = {}\n    for word, freq in word_freq.items():\n        split = splits[word]\n        if len(split) == 1:\n            continue\n        for i in range(len(split) - 1):\n            pair = (split[i], split[i+1])\n            pair_freq[pair] = pair_freq.get(pair, 0) + freq\n    return pair_freq\npair_freq = compute_pair_freq(splits)\nfor i, (pair, freq) in enumerate(pair_freq.items()):\n    print(pair,freq)\n    if i > 5:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:18:56.612645Z","iopub.execute_input":"2025-09-18T04:18:56.612971Z","iopub.status.idle":"2025-09-18T04:18:56.983618Z","shell.execute_reply.started":"2025-09-18T04:18:56.612943Z","shell.execute_reply":"2025-09-18T04:18:56.982339Z"}},"outputs":[{"name":"stdout","text":"('T', 'h') 62926\n('h', 'i') 166820\n('i', 's') 235957\n('Ġ', 'f') 188078\n('f', 'i') 71670\n('i', 'l') 104507\n('l', 'm') 43829\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"most_freq = \"\"\nmax_freq = None\n\nfor pair, freq in pair_freq.items():\n    if max_freq is None or max_freq < freq:\n        most_freq = pair\n        max_freq = freq\nprint(most_freq, max_freq)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:21:26.917373Z","iopub.execute_input":"2025-09-18T04:21:26.917854Z","iopub.status.idle":"2025-09-18T04:21:26.925814Z","shell.execute_reply.started":"2025-09-18T04:21:26.917822Z","shell.execute_reply":"2025-09-18T04:21:26.924701Z"}},"outputs":[{"name":"stdout","text":"('Ġ', 't') 628411\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"def merge_pair(a,b,splits):\n    for word in word_freq.keys():\n        split = splits[word]\n        if len(split) == 1:\n            continue\n        i = 0\n        while i < len(split) - 1:\n            if split[i] == 1 and split[i+1] == b:\n                split = split[:i] + [a + b] + aplit[i+2:]\n            else:\n                i += 1\n        splits[word] = split\n    return splits\nsplits = merge_pair(\"Ġ\", \"t\", splits)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:28:07.588366Z","iopub.execute_input":"2025-09-18T04:28:07.588665Z","iopub.status.idle":"2025-09-18T04:28:07.702953Z","shell.execute_reply.started":"2025-09-18T04:28:07.588646Z","shell.execute_reply":"2025-09-18T04:28:07.701978Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"merges = {}\nvocab_size = 2000\n\nwhile vocab_size > len(vocab):\n    pair_freq = compute_pair_freq(splits)\n    best_pair = \"\"\n    max_freq = None\n    for pair, freq in pair_freq.items():\n        if max_freq is None or max_freq < freq:\n            best_pair = pair\n            max_freq = freq\n    splits = merge_pair(*best_pair,splits)\n    merges[best_pair] = best_pair[0] + best_pair[1]\n    vocab.append(best_pair[0] + best_pair[1])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:35:26.748829Z","iopub.execute_input":"2025-09-18T04:35:26.749197Z","iopub.status.idle":"2025-09-18T04:45:44.358470Z","shell.execute_reply.started":"2025-09-18T04:35:26.749169Z","shell.execute_reply":"2025-09-18T04:45:44.357270Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"def tokenize(text):    \n    word_with_offset = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n    new_words = [word for word, offset in word_with_offset]\n    splits = [[l for l in word] for word in new_words]\n    for pair, merge in merge.items():\n        for idx, split in enumerate(splits):\n            i = 0 \n            while i < len(split) - 1:\n                if split[i] == pair[0] and split[i+1] == pair[1]:\n                    split = split[:i] + [merge] + split[i+2:]\n                else:\n                    i += 1\n            splits[idx] = split\n    return sum(splits, [])\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T04:45:47.839326Z","iopub.execute_input":"2025-09-18T04:45:47.839641Z","iopub.status.idle":"2025-09-18T04:45:47.847720Z","shell.execute_reply.started":"2025-09-18T04:45:47.839615Z","shell.execute_reply":"2025-09-18T04:45:47.846223Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"train_tokenize = tokenize(imdb_train[\"text\"])\n\ndef token","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}