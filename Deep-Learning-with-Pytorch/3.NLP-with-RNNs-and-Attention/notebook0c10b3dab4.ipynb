{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generating Fake Shakespeare Text","metadata":{}},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:21.817522Z","iopub.execute_input":"2025-09-16T04:08:21.817778Z","iopub.status.idle":"2025-09-16T04:08:26.272968Z","shell.execute_reply.started":"2025-09-16T04:08:21.817755Z","shell.execute_reply":"2025-09-16T04:08:26.272199Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(torch.cuda.device_count())\n    device = \"cuda\"\nelif torch.backends.mps.is_available():\n    device = \"mps\"\nelse:\n    device = \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:26.274596Z","iopub.execute_input":"2025-09-16T04:08:26.274956Z","iopub.status.idle":"2025-09-16T04:08:26.396091Z","shell.execute_reply.started":"2025-09-16T04:08:26.274933Z","shell.execute_reply":"2025-09-16T04:08:26.395209Z"},"trusted":true},"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from pathlib import Path\nimport urllib.request\n\ndef download_shakespeare_text():\n    path = Path(\"datasets/shakespeare/shakespeare.txt\")\n    if not path.is_file():\n        path.parent.mkdir(parents=True, exist_ok=True)\n        url = \"https://homl.info/shakespeare\"\n        urllib.request.urlretrieve(url, path)\n    return path.read_text()\nshakespeare_text = download_shakespeare_text()","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:26.397140Z","iopub.execute_input":"2025-09-16T04:08:26.397412Z","iopub.status.idle":"2025-09-16T04:08:27.237103Z","shell.execute_reply.started":"2025-09-16T04:08:26.397383Z","shell.execute_reply":"2025-09-16T04:08:27.236572Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print(shakespeare_text[:100])","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.237762Z","iopub.execute_input":"2025-09-16T04:08:27.238006Z","iopub.status.idle":"2025-09-16T04:08:27.242565Z","shell.execute_reply.started":"2025-09-16T04:08:27.237982Z","shell.execute_reply":"2025-09-16T04:08:27.241710Z"},"trusted":true},"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"vocab = sorted(set(shakespeare_text.lower()))\n''.join(vocab)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.243664Z","iopub.execute_input":"2025-09-16T04:08:27.243920Z","iopub.status.idle":"2025-09-16T04:08:27.270117Z","shell.execute_reply.started":"2025-09-16T04:08:27.243905Z","shell.execute_reply":"2025-09-16T04:08:27.269397Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"char_to_id = {char:idx for idx, char in enumerate(vocab)}\nid_to_char = {idx:char for idx, char in enumerate(vocab)}","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.270792Z","iopub.execute_input":"2025-09-16T04:08:27.270958Z","iopub.status.idle":"2025-09-16T04:08:27.282665Z","shell.execute_reply.started":"2025-09-16T04:08:27.270944Z","shell.execute_reply":"2025-09-16T04:08:27.282074Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"char_to_id[\"a\"]","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.284814Z","iopub.execute_input":"2025-09-16T04:08:27.285011Z","iopub.status.idle":"2025-09-16T04:08:27.297085Z","shell.execute_reply.started":"2025-09-16T04:08:27.284995Z","shell.execute_reply":"2025-09-16T04:08:27.296459Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"13"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"id_to_char[13]","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.297770Z","iopub.execute_input":"2025-09-16T04:08:27.298016Z","iopub.status.idle":"2025-09-16T04:08:27.309495Z","shell.execute_reply.started":"2025-09-16T04:08:27.297993Z","shell.execute_reply":"2025-09-16T04:08:27.308963Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'a'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def encode_text(text):\n    return torch.tensor([char_to_id[char] for char in text.lower()])\ndef decode_text(char_ids):\n    return ''.join([id_to_char[char_id.item()] for char_id in char_ids])","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.310239Z","iopub.execute_input":"2025-09-16T04:08:27.310561Z","iopub.status.idle":"2025-09-16T04:08:27.322805Z","shell.execute_reply.started":"2025-09-16T04:08:27.310543Z","shell.execute_reply":"2025-09-16T04:08:27.322138Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"encoded = encode_text(\"hello world\")\nencoded\n","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.323482Z","iopub.execute_input":"2025-09-16T04:08:27.323693Z","iopub.status.idle":"2025-09-16T04:08:27.369380Z","shell.execute_reply.started":"2025-09-16T04:08:27.323679Z","shell.execute_reply":"2025-09-16T04:08:27.368732Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([20, 17, 24, 24, 27,  1, 35, 27, 30, 24, 16])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"decode_text(encoded)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T04:08:27.370087Z","iopub.execute_input":"2025-09-16T04:08:27.370336Z","iopub.status.idle":"2025-09-16T04:08:27.375073Z","shell.execute_reply.started":"2025-09-16T04:08:27.370315Z","shell.execute_reply":"2025-09-16T04:08:27.374367Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'hello world'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"class TimeSeriesDatasetBuilder:\n    def __init__(self, series, window_length=56):\n        self.encoded_text = encode_text(series)\n        self.window_length = window_length\n   \n    def create_X_y(self):\n        X, y =[],[]\n        for i in range(len(self.encoded_text) - self.window_length):\n            window = self.encoded_text[i:i+self.window_length]\n            future = self.encoded_text[i+1:i+self.window_length+1]\n            X.append(window)\n            y.append(future)\n        return np.array(X),np.array(y)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:12:05.675690Z","iopub.execute_input":"2025-09-16T05:12:05.676301Z","iopub.status.idle":"2025-09-16T05:12:05.681680Z","shell.execute_reply.started":"2025-09-16T05:12:05.676263Z","shell.execute_reply":"2025-09-16T05:12:05.680838Z"},"trusted":true},"outputs":[],"execution_count":94},{"cell_type":"code","source":"to_be_dataset = TimeSeriesDatasetBuilder(series=\"to be or not to be\", window_length=10)\nX,y = to_be_dataset.create_X_y()\nfor i in range(len(X)):\n    decoded_x = decode_text(X[i])\n    decoded_y = decode_text(y[i])\n    print(f\"x : {decoded_x}\")\n    print(f\"y : {decoded_y}\")","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:12:07.845140Z","iopub.execute_input":"2025-09-16T05:12:07.845410Z","iopub.status.idle":"2025-09-16T05:12:07.851847Z","shell.execute_reply.started":"2025-09-16T05:12:07.845391Z","shell.execute_reply":"2025-09-16T05:12:07.851167Z"},"trusted":true},"outputs":[{"name":"stdout","text":"x : to be or n\ny : o be or no\nx : o be or no\ny :  be or not\nx :  be or not\ny : be or not \nx : be or not \ny : e or not t\nx : e or not t\ny :  or not to\nx :  or not to\ny : or not to \nx : or not to \ny : r not to b\nx : r not to b\ny :  not to be\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"window_length = 56\nbatch_size = 1024 \nbuilder = TimeSeriesDatasetBuilder(shakespeare_text,window_length)\nX, y = builder.create_X_y()","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:12:12.935282Z","iopub.execute_input":"2025-09-16T05:12:12.935635Z","iopub.status.idle":"2025-09-16T05:12:33.464333Z","shell.execute_reply.started":"2025-09-16T05:12:12.935602Z","shell.execute_reply":"2025-09-16T05:12:33.463590Z"},"trusted":true},"outputs":[],"execution_count":96},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:12:50.980391Z","iopub.execute_input":"2025-09-16T05:12:50.981070Z","iopub.status.idle":"2025-09-16T05:12:50.986108Z","shell.execute_reply.started":"2025-09-16T05:12:50.981046Z","shell.execute_reply":"2025-09-16T05:12:50.985329Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"(1115338, 56)"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:12:57.640997Z","iopub.execute_input":"2025-09-16T05:12:57.641556Z","iopub.status.idle":"2025-09-16T05:12:57.646202Z","shell.execute_reply.started":"2025-09-16T05:12:57.641509Z","shell.execute_reply":"2025-09-16T05:12:57.645462Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"(1115338, 56)"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\nX_tensor = torch.tensor(X, dtype = torch.long)\ny_tensor = torch.tensor(y, dtype = torch.long).squeeze(-1)\n\ntrain_set = TensorDataset(X_tensor[:1_000_000], y_tensor[:1_000_000])\nvalid_set = TensorDataset(X_tensor[1_000_000:1_060_000],y_tensor[1_000_000:1_060_000])\ntest_set = TensorDataset(X_tensor[1_060_000:], y_tensor[1_060_000:])\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n                          num_workers=2, pin_memory=True)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size,\n                         num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size,\n                        num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:13:15.465138Z","iopub.execute_input":"2025-09-16T05:13:15.465429Z","iopub.status.idle":"2025-09-16T05:13:15.730645Z","shell.execute_reply.started":"2025-09-16T05:13:15.465409Z","shell.execute_reply":"2025-09-16T05:13:15.729840Z"},"trusted":true},"outputs":[],"execution_count":101},{"cell_type":"code","source":"import torchmetrics\n\ndef evaluate_tm(model, data_loader, metric):\n    model.eval()\n    metric.reset()\n    with torch.no_grad():\n        for X_batch, y_batch in data_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred = model(X_batch)\n            metric.update(y_pred, y_batch)\n    return metric.compute()\n\ndef train(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs, patience=2,\n         factor=0.5,epoch_callback=None):\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode=\"max\", patience=patience, factor=factor\n    )\n    history = {\"train_losses\":[],\"train_metrics\":[],\"valid_metrics\":[]}\n    for epoch in range(n_epochs):\n        total_loss = 0\n        metric.reset()\n        model.train()\n        if epoch_callback is not None:\n            epoch_callback(model,epoch)\n        for idx,( X_batch, y_batch) in enumerate(train_loader):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred = model(X_batch)\n            loss = criterion(y_pred, y_batch)\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            metric.update(y_pred, y_batch)\n            print(f\"\\rBatch {idx+1}/{len(train_loader)}\", end=\"\")\n            print(f\", loss ={total_loss/(idx+1 ):.4f}\", end=\"\")\n        mean_loss = total_loss / len(train_loader)\n        history[\"train_losses\"].append(mean_loss)\n        history[\"train_metrics\"].append(metric.compute().item())\n        val_metric = evaluate_tm(model, valid_loader, metric).item()\n        history[\"valid_metrics\"].append(val_metric)\n        scheduler.step(val_metric)\n        print(f\"Epoch:{epoch+1}/{n_epochs}, \"\n             f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n             f\"Train Metric: {history['train_metrics'][-1]:.4f}, \"\n             f\"Valid Metric: {history['valid_metrics'][-1]:.4f}\")\n    return history","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:53:24.841265Z","iopub.execute_input":"2025-09-16T05:53:24.841608Z","iopub.status.idle":"2025-09-16T05:53:24.851898Z","shell.execute_reply.started":"2025-09-16T05:53:24.841583Z","shell.execute_reply":"2025-09-16T05:53:24.850991Z"},"trusted":true},"outputs":[],"execution_count":158},{"cell_type":"code","source":"class ShakespeareModel(nn.Module):\n    def __init__(self, vocab_size, n_hidden=128, n_layers=2, embed_size=20, dropout=0.1):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_size)\n        self.gru = nn.GRU(embed_size, n_hidden, num_layers=n_layers,\n                         batch_first=True, dropout=dropout)\n        self.output = nn.Linear(n_hidden, vocab_size)\n        \n    def forward(self, X):\n        embeddings = self.embed(X)\n        outputs, _states = self.gru(embeddings)\n        return self.output(outputs).permute(0,2,1)\nmodel = ShakespeareModel(len(vocab)).to(device)\nif torch.cuda.device_count()>1:\n    print(\"Using\", torch.cuda.device_count(),\"GPU's\")\n    model = nn.DataParallel(model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:14:18.336003Z","iopub.execute_input":"2025-09-16T05:14:18.336965Z","iopub.status.idle":"2025-09-16T05:14:18.352225Z","shell.execute_reply.started":"2025-09-16T05:14:18.336938Z","shell.execute_reply":"2025-09-16T05:14:18.351594Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using 2 GPU's\n","output_type":"stream"},{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): ShakespeareModel(\n    (embed): Embedding(39, 20)\n    (gru): GRU(20, 128, num_layers=2, batch_first=True, dropout=0.1)\n    (output): Linear(in_features=128, out_features=39, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":105},{"cell_type":"code","source":"n_epochs = 20\nxentropy = nn.CrossEntropyLoss()\naccuracy = torchmetrics.Accuracy(task=\"multiclass\",num_classes=len(vocab)).to(device)\noptimizer = torch.optim.NAdam(model.parameters())\n\nhistory = train(model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:14:20.435581Z","iopub.execute_input":"2025-09-16T05:14:20.436333Z","iopub.status.idle":"2025-09-16T05:21:34.286068Z","shell.execute_reply.started":"2025-09-16T05:14:20.436308Z","shell.execute_reply":"2025-09-16T05:21:34.285216Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Batch 977/977, loss =1.7053Epoch:1/20, Train Loss: 1.7053, Train Metric: 0.4877, Valid Metric: 0.5337\nBatch 977/977, loss =1.3972Epoch:2/20, Train Loss: 1.3972, Train Metric: 0.5644, Valid Metric: 0.5487\nBatch 977/977, loss =1.3526Epoch:3/20, Train Loss: 1.3526, Train Metric: 0.5755, Valid Metric: 0.5519\nBatch 977/977, loss =1.3312Epoch:4/20, Train Loss: 1.3312, Train Metric: 0.5810, Valid Metric: 0.5516\nBatch 977/977, loss =1.3185Epoch:5/20, Train Loss: 1.3185, Train Metric: 0.5843, Valid Metric: 0.5518\nBatch 977/977, loss =1.3101Epoch:6/20, Train Loss: 1.3101, Train Metric: 0.5865, Valid Metric: 0.5536\nBatch 977/977, loss =1.3044Epoch:7/20, Train Loss: 1.3044, Train Metric: 0.5879, Valid Metric: 0.5533\nBatch 977/977, loss =1.3000Epoch:8/20, Train Loss: 1.3000, Train Metric: 0.5891, Valid Metric: 0.5523\nBatch 977/977, loss =1.2966Epoch:9/20, Train Loss: 1.2966, Train Metric: 0.5899, Valid Metric: 0.5530\nBatch 977/977, loss =1.2891Epoch:10/20, Train Loss: 1.2891, Train Metric: 0.5921, Valid Metric: 0.5542\nBatch 977/977, loss =1.2874Epoch:11/20, Train Loss: 1.2874, Train Metric: 0.5925, Valid Metric: 0.5542\nBatch 977/977, loss =1.2861Epoch:12/20, Train Loss: 1.2861, Train Metric: 0.5929, Valid Metric: 0.5548\nBatch 977/977, loss =1.2850Epoch:13/20, Train Loss: 1.2850, Train Metric: 0.5932, Valid Metric: 0.5543\nBatch 977/977, loss =1.2838Epoch:14/20, Train Loss: 1.2838, Train Metric: 0.5935, Valid Metric: 0.5547\nBatch 977/977, loss =1.2828Epoch:15/20, Train Loss: 1.2828, Train Metric: 0.5937, Valid Metric: 0.5543\nBatch 977/977, loss =1.2793Epoch:16/20, Train Loss: 1.2793, Train Metric: 0.5948, Valid Metric: 0.5547\nBatch 977/977, loss =1.2786Epoch:17/20, Train Loss: 1.2786, Train Metric: 0.5949, Valid Metric: 0.5546\nBatch 977/977, loss =1.2782Epoch:18/20, Train Loss: 1.2782, Train Metric: 0.5951, Valid Metric: 0.5535\nBatch 977/977, loss =1.2762Epoch:19/20, Train Loss: 1.2762, Train Metric: 0.5956, Valid Metric: 0.5548\nBatch 977/977, loss =1.2758Epoch:20/20, Train Loss: 1.2758, Train Metric: 0.5957, Valid Metric: 0.5544\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"# Critical Shape Journey\n\n# X (Input) Path:\n\n#→ windowing → [1115294, 56] \n#→ batching → [1024, 56]\n#→ embed() → [1024, 56, 10]\n#→ GRU() → [1024, 56, 128] \n#→ [:, -1, :] → [1024, 128]\n#→ Linear() → [1024, 39]\n\n# y (Target) Path:\n\n# → windowing → [1115294, 1] \n# → squeeze(-1) → [1115294]\n# → batching → [1024]\n# → CrossEntropyLoss with [1024, 39]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T04:19:48.280330Z","iopub.execute_input":"2025-09-16T04:19:48.280681Z","iopub.status.idle":"2025-09-16T04:19:48.284871Z","shell.execute_reply.started":"2025-09-16T04:19:48.280654Z","shell.execute_reply":"2025-09-16T04:19:48.284184Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"torch.save(model.state_dict(), \"my_shakespeare_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:21:38.637085Z","iopub.execute_input":"2025-09-16T05:21:38.637362Z","iopub.status.idle":"2025-09-16T05:21:38.645068Z","shell.execute_reply.started":"2025-09-16T05:21:38.637341Z","shell.execute_reply":"2025-09-16T05:21:38.644259Z"},"trusted":true},"outputs":[],"execution_count":109},{"cell_type":"code","source":"text = \"To be or not to b\"\nencoded_text = encode_text(text).unsqueeze(dim=0).to(device)\nencoded_text.shape","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:21:40.426811Z","iopub.execute_input":"2025-09-16T05:21:40.427370Z","iopub.status.idle":"2025-09-16T05:21:40.432853Z","shell.execute_reply.started":"2025-09-16T05:21:40.427346Z","shell.execute_reply":"2025-09-16T05:21:40.432275Z"},"trusted":true},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 17])"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    y_logits = model(encoded_text)\n    predicted_char_id = y_logits[0,:,-1].argmax().item()\n    predicted_char = id_to_char[predicted_char_id]\npredicted_char","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:23:05.701586Z","iopub.execute_input":"2025-09-16T05:23:05.701872Z","iopub.status.idle":"2025-09-16T05:23:05.710108Z","shell.execute_reply.started":"2025-09-16T05:23:05.701853Z","shell.execute_reply":"2025-09-16T05:23:05.709324Z"},"trusted":true},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"'e'"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"def next_char(model, text, temperature=0.7):\n    model.eval()\n    encoded_text = encode_text(text).unsqueeze(0).to(device)\n    with torch.no_grad():\n        y_logits = model(encoded_text)\n        y_probas = torch.softmax(y_logits[0,:,-1]/temperature, dim=-1)\n        predicted_char_id = torch.multinomial(y_probas,num_samples=1).item()     \n        return id_to_char[predicted_char_id]\n\n","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:23:06.936902Z","iopub.execute_input":"2025-09-16T05:23:06.937372Z","iopub.status.idle":"2025-09-16T05:23:06.942105Z","shell.execute_reply.started":"2025-09-16T05:23:06.937349Z","shell.execute_reply":"2025-09-16T05:23:06.941284Z"},"trusted":true},"outputs":[],"execution_count":119},{"cell_type":"code","source":"import time\ndef generate_text(model, text, n_chars=100,temperature=0.7):\n    print(text, end='', flush=True)\n    for _ in range(n_chars):\n        char = next_char(model, text, temperature)\n        text += char\n        print(char, end='', flush=True)\n        time.sleep(0.01)","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:23:08.496604Z","iopub.execute_input":"2025-09-16T05:23:08.497164Z","iopub.status.idle":"2025-09-16T05:23:08.501696Z","shell.execute_reply.started":"2025-09-16T05:23:08.497145Z","shell.execute_reply":"2025-09-16T05:23:08.500763Z"},"trusted":true},"outputs":[],"execution_count":120},{"cell_type":"code","source":"print(generate_text(model,\"To be or not to b\",n_chars=500 ))","metadata":{"execution":{"iopub.status.busy":"2025-09-16T05:23:10.057198Z","iopub.execute_input":"2025-09-16T05:23:10.057477Z","iopub.status.idle":"2025-09-16T05:23:16.742854Z","shell.execute_reply.started":"2025-09-16T05:23:10.057458Z","shell.execute_reply":"2025-09-16T05:23:16.742048Z"},"trusted":true},"outputs":[{"name":"stdout","text":"To be or not to be all.\n\nfirst citizen:\nthen have you hear and tender, and the king guess\nin him to her weak to thy company:\nmy lord, i know not, gentle friends, who hath he presently of your own care\nin his friends thee to be proclamation. an if you\nhave one the devil. richard comes:\ni will be reason what you were thee sorrow peers.\n\ngloucester:\nno, madam, but in her ready?\n\npaulina:\nso say you,\nshould leave and part would not be so your fatoly walls,\nmy duke of york:\nhe did writ in this be crain: he shall not None\n","output_type":"stream"}],"execution_count":121},{"cell_type":"markdown","source":"## Statefull RNN","metadata":{}},{"cell_type":"code","source":"class DatasetBuilderStateful:\n    def __init__(self, series, window_length=56, horizon = 1, batch_size = 5):\n        self.encoded_text = encode_text(series)\n        self.window_length = window_length\n        self.horizon = horizon\n        self.batch_size = batch_size\n\n        #total number of full windows\n        self.n_consecutive_windows = (len(self.encoded_text) - self.horizon) // self.window_length\n        #windows per stream\n        self.n_windows_per_stream = self.n_consecutive_windows // self.batch_size\n        #spacing between streams\n        self.spacing = self.n_windows_per_stream * self.window_length\n        #Total samples\n        self.length = self.n_windows_per_stream * self.batch_size\n                \n    def create_X_y(self):\n        X, y =[],[]\n        for i in range(self.length):\n            slot = i % self.batch_size  # stream index\n            window_no_in_slot = i // self.batch_size\n\n            start = slot * self.spacing + window_no_in_slot * self.window_length\n            end = start + self.window_length\n            window = self.encoded_text[start:end]\n            future = self.encoded_text[start+1:end+1]\n            X.append(window)\n            y.append(future)\n        return np.array(X),np.array(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:58:07.517268Z","iopub.execute_input":"2025-09-16T05:58:07.518105Z","iopub.status.idle":"2025-09-16T05:58:07.524607Z","shell.execute_reply.started":"2025-09-16T05:58:07.518080Z","shell.execute_reply":"2025-09-16T05:58:07.523607Z"}},"outputs":[],"execution_count":174},{"cell_type":"code","source":"batch_size =1024\nbuilder = DatasetBuilderStateful(shakespeare_text, batch_size=batch_size)\nX_dataset, y_dataset = builder.create_X_y()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:58:09.457080Z","iopub.execute_input":"2025-09-16T05:58:09.457355Z","iopub.status.idle":"2025-09-16T05:58:10.130010Z","shell.execute_reply.started":"2025-09-16T05:58:09.457335Z","shell.execute_reply":"2025-09-16T05:58:10.129300Z"}},"outputs":[],"execution_count":175},{"cell_type":"code","source":"X_tensor = torch.tensor(X_dataset, dtype=torch.long)\ny_tensor = torch.tensor(y_dataset, dtype=torch.long)\ntrain_set = TensorDataset(X_tensor[:1_000_000], y_tensor[:1_000_000])\nvalid_set = TensorDataset(X_tensor[1_000_000:1_060_000],y_tensor[1_000_000:1_060_000])\ntest_set = TensorDataset(X_tensor[1_060_000:], y_tensor[1_060_000:])\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size,\n                          num_workers=2, pin_memory=True)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size,\n                         num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size,\n                        num_workers=2, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:58:11.111375Z","iopub.execute_input":"2025-09-16T05:58:11.111982Z","iopub.status.idle":"2025-09-16T05:58:11.119965Z","shell.execute_reply.started":"2025-09-16T05:58:11.111962Z","shell.execute_reply":"2025-09-16T05:58:11.119292Z"}},"outputs":[],"execution_count":176},{"cell_type":"code","source":"class StatefulShakespeareModel(nn.Module):\n    def __init__(self, vocab_size, n_layers=2, embed_size=20, n_hidden=128, dropout=0.1):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_size)\n        self.gru = nn.GRU(embed_size, n_hidden, num_layers=n_layers,batch_first=True,\n                         dropout=dropout)\n        self.output = nn.Linear(n_hidden,vocab_size)\n        self.hidden_states = None\n\n    def forward(self,X):\n        embeddings = self.embed(X)\n        outputs, hidden_states = self.gru(embeddings,self.hidden_states)\n        self.hidden_states = hidden_states.detach()\n        return self.output(outputs).permute(0,2,1)        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:58:13.822064Z","iopub.execute_input":"2025-09-16T05:58:13.822316Z","iopub.status.idle":"2025-09-16T05:58:13.827732Z","shell.execute_reply.started":"2025-09-16T05:58:13.822298Z","shell.execute_reply":"2025-09-16T05:58:13.826896Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"stateful_model = StatefulShakespeareModel(len(vocab)).to(device)\nn_epochs = 20\n\ndef reset_hidden_state(model,epoch):\n    model.hidden_states = None\n\nxentropy = nn.CrossEntropyLoss()\naccuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(vocab)).to(device)\noptimizer = torch.optim.NAdam(stateful_model.parameters())\n\nhistory = train(stateful_model, optimizer, xentropy, accuracy, train_loader, \n                valid_loader,n_epochs, epoch_callback=reset_hidden_state)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T05:58:15.616432Z","iopub.execute_input":"2025-09-16T05:58:15.616712Z","iopub.status.idle":"2025-09-16T05:58:35.664167Z","shell.execute_reply.started":"2025-09-16T05:58:15.616693Z","shell.execute_reply":"2025-09-16T05:58:35.663347Z"}},"outputs":[{"name":"stdout","text":"Batch 19/19, loss =3.1637Epoch:1/20, Train Loss: 3.1637, Train Metric: 0.1497, Valid Metric: 0.0000\nBatch 19/19, loss =2.7668Epoch:2/20, Train Loss: 2.7668, Train Metric: 0.2330, Valid Metric: 0.0000\nBatch 19/19, loss =2.5069Epoch:3/20, Train Loss: 2.5069, Train Metric: 0.2916, Valid Metric: 0.0000\nBatch 19/19, loss =2.3347Epoch:4/20, Train Loss: 2.3347, Train Metric: 0.3303, Valid Metric: 0.0000\nBatch 19/19, loss =2.2242Epoch:5/20, Train Loss: 2.2242, Train Metric: 0.3573, Valid Metric: 0.0000\nBatch 19/19, loss =2.1656Epoch:6/20, Train Loss: 2.1656, Train Metric: 0.3733, Valid Metric: 0.0000\nBatch 19/19, loss =2.1138Epoch:7/20, Train Loss: 2.1138, Train Metric: 0.3837, Valid Metric: 0.0000\nBatch 19/19, loss =2.0762Epoch:8/20, Train Loss: 2.0762, Train Metric: 0.3911, Valid Metric: 0.0000\nBatch 19/19, loss =2.0526Epoch:9/20, Train Loss: 2.0526, Train Metric: 0.3966, Valid Metric: 0.0000\nBatch 19/19, loss =2.0301Epoch:10/20, Train Loss: 2.0301, Train Metric: 0.4015, Valid Metric: 0.0000\nBatch 19/19, loss =2.0129Epoch:11/20, Train Loss: 2.0129, Train Metric: 0.4052, Valid Metric: 0.0000\nBatch 19/19, loss =2.0019Epoch:12/20, Train Loss: 2.0019, Train Metric: 0.4081, Valid Metric: 0.0000\nBatch 19/19, loss =1.9913Epoch:13/20, Train Loss: 1.9913, Train Metric: 0.4108, Valid Metric: 0.0000\nBatch 19/19, loss =1.9825Epoch:14/20, Train Loss: 1.9825, Train Metric: 0.4131, Valid Metric: 0.0000\nBatch 19/19, loss =1.9775Epoch:15/20, Train Loss: 1.9775, Train Metric: 0.4144, Valid Metric: 0.0000\nBatch 19/19, loss =1.9720Epoch:16/20, Train Loss: 1.9720, Train Metric: 0.4161, Valid Metric: 0.0000\nBatch 19/19, loss =1.9677Epoch:17/20, Train Loss: 1.9677, Train Metric: 0.4175, Valid Metric: 0.0000\nBatch 19/19, loss =1.9651Epoch:18/20, Train Loss: 1.9651, Train Metric: 0.4181, Valid Metric: 0.0000\nBatch 19/19, loss =1.9622Epoch:19/20, Train Loss: 1.9622, Train Metric: 0.4188, Valid Metric: 0.0000\nBatch 19/19, loss =1.9600Epoch:20/20, Train Loss: 1.9600, Train Metric: 0.4195, Valid Metric: 0.0000\n","output_type":"stream"}],"execution_count":178}]}