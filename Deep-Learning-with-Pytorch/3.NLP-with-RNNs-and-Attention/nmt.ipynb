{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13114139,"sourceType":"datasetVersion","datasetId":8307286}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport numpy as np\nimport pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:51.030228Z","iopub.execute_input":"2025-09-20T07:26:51.030542Z","iopub.status.idle":"2025-09-20T07:26:51.034026Z","shell.execute_reply.started":"2025-09-20T07:26:51.030520Z","shell.execute_reply":"2025-09-20T07:26:51.033486Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\n    print(torch.cuda.device_count())\nelif torch.backends.mps.is_available():\n    device = \"mps\"\nelse:\n    device = \"cpu\"\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:51.084917Z","iopub.execute_input":"2025-09-20T07:26:51.085525Z","iopub.status.idle":"2025-09-20T07:26:51.090783Z","shell.execute_reply.started":"2025-09-20T07:26:51.085505Z","shell.execute_reply":"2025-09-20T07:26:51.090226Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"data = []\nfilename = \"/kaggle/input/eng-spa/spa.txt\"\nwith open(filename, \"r\") as f:\n    for line in f:\n        data.append(line.strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:51.114990Z","iopub.execute_input":"2025-09-20T07:26:51.115447Z","iopub.status.idle":"2025-09-20T07:26:51.167049Z","shell.execute_reply.started":"2025-09-20T07:26:51.115395Z","shell.execute_reply":"2025-09-20T07:26:51.166304Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"cleaned_data = [line.replace(\"¡\", \"\").replace(\"¿\", \"\") for line in data]\npairs = [line.split(\"\\t\") for line in cleaned_data]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:51.168167Z","iopub.execute_input":"2025-09-20T07:26:51.168441Z","iopub.status.idle":"2025-09-20T07:26:51.811799Z","shell.execute_reply.started":"2025-09-20T07:26:51.168398Z","shell.execute_reply":"2025-09-20T07:26:51.810671Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"np.random.shuffle(pairs)\neng_sentences, es_sentences = zip(*pairs)\nfor i in range(3):\n    print(eng_sentences[i], \"==>\" ,es_sentences[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:51.813508Z","iopub.execute_input":"2025-09-20T07:26:51.813883Z","iopub.status.idle":"2025-09-20T07:26:51.922375Z","shell.execute_reply.started":"2025-09-20T07:26:51.813857Z","shell.execute_reply":"2025-09-20T07:26:51.921590Z"}},"outputs":[{"name":"stdout","text":"Tom might have left his umbrella in Mary's car. ==> Puede que a Tom se le haya quedado el paraguas en el auto de Mary.\nWe believe that Tom killed Mary with an ice pick. ==> Creemos que Tom mató a Mary con un picahielos.\nI am disappointed. ==> Estoy decepcionado.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:51.923172Z","iopub.execute_input":"2025-09-20T07:26:51.923572Z","iopub.status.idle":"2025-09-20T07:26:52.341922Z","shell.execute_reply.started":"2025-09-20T07:26:51.923547Z","shell.execute_reply":"2025-09-20T07:26:52.341325Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"max_len = 100\ndef encode_with_gpt2(sentence, add_sos_and_eos=False):\n    \n    texts = [f\"<s> {s} </s>\" if add_sos_and_eos else s for s in sentence]\n    encodings = tokenizer(\n        texts,\n        padding=True,\n        truncation=True,\n        max_length=max_len,\n        return_tensors=\"pt\"\n    )\n    return encodings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.343583Z","iopub.execute_input":"2025-09-20T07:26:52.343849Z","iopub.status.idle":"2025-09-20T07:26:52.347982Z","shell.execute_reply.started":"2025-09-20T07:26:52.343831Z","shell.execute_reply":"2025-09-20T07:26:52.347374Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass TranslationDataset(Dataset):\n    def __init__(self, src_sentences, tgt_sentences, tokenizer, max_len=500):\n        self.src_sentences = src_sentences\n        self.tgt_sentences = tgt_sentences\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.src_sentences)\n\n    def __getitem__(self,idx):\n        src = self.src_sentences[idx]\n        tgt = f\"<s> {self.tgt_sentences[idx]} </s>\"\n\n        src_enc = self.tokenizer(\n            src,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_len,\n            return_tensors=\"pt\")\n        tgt_enc = self.tokenizer(\n            tgt,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_len,\n            return_tensors=\"pt\")\n\n        decoder_input_ids = tgt_enc[\"input_ids\"][:,:-1].squeeze(0)\n        labels = tgt_enc[\"input_ids\"][:,1:].squeeze(0)\n\n        return {\n            \"encoder_input_ids\":src_enc[\"input_ids\"].squeeze(0),\n            \"encoder_attention_mask\":src_enc[\"attention_mask\"].squeeze(0),\n            \"decoder_input_ids\":decoder_input_ids,\n            \"labels\":labels\n        } ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.348753Z","iopub.execute_input":"2025-09-20T07:26:52.349050Z","iopub.status.idle":"2025-09-20T07:26:52.362219Z","shell.execute_reply.started":"2025-09-20T07:26:52.349029Z","shell.execute_reply":"2025-09-20T07:26:52.361734Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nclass Encoder(nn.Module):\n    def __init__(self, pretrained_embed, n_hidden=2, hidden_size=128,dropout=0.2):\n        super().__init__()\n        weights = pretrained_embed.weight.data\n        self.embed = nn.Embedding.from_pretrained(weights,freeze=True)\n        embed_size = weights.shape[-1]\n        self.gru = nn.GRU(embed_size, hidden_size, num_layers=n_hidden,\n                         batch_first=True, dropout=dropout, bidirectional=True)\n\n    def forward(self, input_ids, attention_mask):\n        embeddings = self.embed(input_ids)\n        lengths = attention_mask.sum(dim=1)\n        packed = pack_padded_sequence(embeddings,\n                                     lengths = lengths.cpu(),\n                                     batch_first=True,\n                                     enforce_sorted=False)\n        outputs, hidden = self.gru(packed)\n        outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length=input_ids.size(1))\n        return outputs, hidden    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.363048Z","iopub.execute_input":"2025-09-20T07:26:52.363355Z","iopub.status.idle":"2025-09-20T07:26:52.380751Z","shell.execute_reply.started":"2025-09-20T07:26:52.363333Z","shell.execute_reply":"2025-09-20T07:26:52.380059Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, pretrained_embed, n_hidden=2, hidden_size=128):\n        super().__init__()\n        weights = pretrained_embed.weight.data\n        self.embed = nn.Embedding.from_pretrained(weights,freeze=True)\n        embed_size = weights.shape[-1]\n        self.gru = nn.GRU(embed_size, hidden_size*2,num_layers=n_hidden,\n                          batch_first=True)\n        self.output = nn.Linear(hidden_size*2, weights.shape[0])\n\n    def forward(self, input_ids, hidden):\n        embeddings = self.embed(input_ids)\n        outputs, hidden = self.gru(embeddings, hidden)\n        logits = self.output(outputs)\n        return logits, hidden       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.381531Z","iopub.execute_input":"2025-09-20T07:26:52.381767Z","iopub.status.idle":"2025-09-20T07:26:52.397533Z","shell.execute_reply.started":"2025-09-20T07:26:52.381746Z","shell.execute_reply":"2025-09-20T07:26:52.396991Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()   \n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src_ids, src_mask, tgt_ids):\n        enc_outputs, enc_hidden = self.encoder(src_ids, src_mask)\n        logits, _ = self.decoder(tgt_ids, enc_hidden)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.398193Z","iopub.execute_input":"2025-09-20T07:26:52.398499Z","iopub.status.idle":"2025-09-20T07:26:52.410061Z","shell.execute_reply.started":"2025-09-20T07:26:52.398480Z","shell.execute_reply":"2025-09-20T07:26:52.409367Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"import transformers\n\ngpt_model = transformers.AutoModel.from_pretrained(\"gpt2\")\nvocab_size = gpt_model.get_input_embeddings().weight.data.shape[0]\nvocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.410809Z","iopub.execute_input":"2025-09-20T07:26:52.411042Z","iopub.status.idle":"2025-09-20T07:26:52.595875Z","shell.execute_reply.started":"2025-09-20T07:26:52.411022Z","shell.execute_reply":"2025-09-20T07:26:52.595290Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"50257"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\neng_train, eng_valid, es_train, es_valid = train_test_split(\n    eng_sentences, es_sentences, test_size = 0.20\n)\n\nbatch_size = 128\n\ntrain_dataset = TranslationDataset(eng_train, es_train, tokenizer)\nvalid_dataset = TranslationDataset(eng_valid, es_valid, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.597408Z","iopub.execute_input":"2025-09-20T07:26:52.597631Z","iopub.status.idle":"2025-09-20T07:26:52.659344Z","shell.execute_reply.started":"2025-09-20T07:26:52.597615Z","shell.execute_reply":"2025-09-20T07:26:52.658677Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"import torchmetrics\n\ndef evaluate_tm(model, data_loader, metric):\n    model.eval()\n    metric.reset()\n    with torch.no_grad():\n        for batch in data_loader:\n            src_ids = batch[\"encoder_input_ids\"].to(device)\n            src_mask = batch[\"encoder_attention_mask\"].to(device)\n            tgt_ids = batch[\"decoder_input_ids\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            y_pred = model(src_ids, src_mask, tgt_ids)\n            metric.update(y_pred.view(-1,vocab_size), labels.view(-1))\n    return metric.compute\n            \ndef train(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs):\n    history = {\"train_losses\":[],\"train_metrics\":[],\"valid_metrics\":[]}\n    for epoch in range(n_epochs):\n        total_loss = 0\n        metric.reset()\n        model.train()\n        for idx, batch in enumerate(train_loader):\n            src_ids = batch[\"encoder_input_ids\"].to(device)\n            src_mask = batch[\"encoder_attention_mask\"].to(device)\n            tgt_ids = batch[\"decoder_input_ids\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            y_pred = model(src_ids, src_mask, tgt_ids)\n            loss = criterion(y_pred.view(-1,vocab_size), labels.view(-1))\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            metric.update(y_pred.view(-1,vocab_size), labels.view(-1))\n            print(f\"\\rBatch {idx+1}/{len(train_loader)}\", end=\"\")\n            print(f\", loss ={total_loss/(idx+1 ):.4f} \", end=\"\")\n        mean_loss = total_loss / len(train_loader)\n        history[\"train_losses\"].append(mean_loss)\n        history[\"train_metrics\"].append(metric.compute().item())\n        val_metric = evaluate_tm(model, valid_loader, metric).item()\n        history[\"valid_metrics\"].append(val_metric)\n        print(f\"Epoch:{epoch+1}/{n_epochs}, \"\n             f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n             f\"Train Metric: {history['train_metrics'][-1]:.4f}%, \"\n             f\"Valid Metric: {history['valid_metrics'][-1]:.4f}%\")\n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.659967Z","iopub.execute_input":"2025-09-20T07:26:52.660155Z","iopub.status.idle":"2025-09-20T07:26:52.675294Z","shell.execute_reply.started":"2025-09-20T07:26:52.660140Z","shell.execute_reply":"2025-09-20T07:26:52.674570Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"encoder = Encoder(gpt_model.get_input_embeddings())\ndecoder = Decoder(gpt_model.get_input_embeddings())\n\nnmt_model = Seq2Seq(encoder, decoder).to(device)\n\noptimizer = torch.optim.NAdam(nmt_model.parameters())\nxentropy = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\naccuracy = torchmetrics.Accuracy(task=\"multiclass\",num_classes = vocab_size)\nn_epochs=20\n\nhistory = train(nmt_model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T07:26:52.676087Z","iopub.execute_input":"2025-09-20T07:26:52.676335Z","iopub.status.idle":"2025-09-20T07:26:53.466335Z","shell.execute_reply.started":"2025-09-20T07:26:52.676319Z","shell.execute_reply":"2025-09-20T07:26:53.465346Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1757507713.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3984289229.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/78868229.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_ids, src_mask, tgt_ids)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/940545107.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, hidden)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1389\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m             result = _VF.gru(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    345\u001b[0m     ) -> None:\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (2, 128, 256), got [4, 128, 128]"],"ename":"RuntimeError","evalue":"Expected hidden size (2, 128, 256), got [4, 128, 128]","output_type":"error"}],"execution_count":72}]}