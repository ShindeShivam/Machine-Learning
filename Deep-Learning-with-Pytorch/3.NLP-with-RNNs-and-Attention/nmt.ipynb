{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13123799,"sourceType":"datasetVersion","datasetId":8313502}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport json","metadata":{"id":"RunX_vFqQaRn","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:23.402250Z","iopub.execute_input":"2025-09-21T08:02:23.402774Z","iopub.status.idle":"2025-09-21T08:02:23.406449Z","shell.execute_reply.started":"2025-09-21T08:02:23.402750Z","shell.execute_reply":"2025-09-21T08:02:23.405556Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\n    print(torch.cuda.device_count())\nelif torch.backends.mps.is_available():\n    device = \"mps\"\nelse:\n    device = \"cpu\"\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"V8glhYZZVUy7","outputId":"fc2fd6d1-680c-420f-d2f0-f1ad6bcb6ed2","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:23.407552Z","iopub.execute_input":"2025-09-21T08:02:23.407863Z","iopub.status.idle":"2025-09-21T08:02:23.423745Z","shell.execute_reply.started":"2025-09-21T08:02:23.407836Z","shell.execute_reply":"2025-09-21T08:02:23.423167Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Data Loading","metadata":{"id":"doavUtPbVrot"}},{"cell_type":"code","source":"data = []\nfilename = \"/kaggle/input/english-hinglish-text/hinglish_upload_v1.json\"\n\nwith open(filename, \"r\", encoding=\"utf-8\") as f:\n  for line in f:\n    obj = json.loads(line)\n    data.append({\n        \"English\":obj[\"translation\"][\"en\"],\n        \"Hinglish\":obj[\"translation\"][\"hi_ng\"]\n    })\n","metadata":{"id":"L654n9RxRkla","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:23.424840Z","iopub.execute_input":"2025-09-21T08:02:23.425139Z","iopub.status.idle":"2025-09-21T08:02:23.953768Z","shell.execute_reply.started":"2025-09-21T08:02:23.425122Z","shell.execute_reply":"2025-09-21T08:02:23.953163Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"df = pd.DataFrame(data)\ndf = df.sample(frac=1).reset_index(drop=True)\n\ndef preprocess_text(text):\n  return str(text).strip()\n\nen_sentence = df[\"English\"].apply(preprocess_text).tolist()\nhing_sentence = df[\"Hinglish\"].apply(preprocess_text).tolist()\n\nfor i in range(3):\n    print(en_sentence[i], \"=>\", hing_sentence[i])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6jBbQButTO3j","outputId":"bf9d6030-01ef-44d3-debf-6b9e020e4a6a","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:23.954428Z","iopub.execute_input":"2025-09-21T08:02:23.954648Z","iopub.status.idle":"2025-09-21T08:02:24.259567Z","shell.execute_reply.started":"2025-09-21T08:02:23.954632Z","shell.execute_reply":"2025-09-21T08:02:24.258706Z"}},"outputs":[{"name":"stdout","text":"Does it look like we are headed for a thunderstorm ? => kya ye lagta hai ki hum thunderstorm ke jaa rahe hai ?\nIs there heavy road construction on the way to Fargo at this time ? => Kya is time par Fargo ke raaste me heavy road construction chal raha hai ?\nText my location to my brother . => mere bhai ko mera location text karo\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Tokenization","metadata":{"id":"27DEv6xvVy00"}},{"cell_type":"code","source":"import tokenizers\ndef train_eng_hing():\n  for en, hi in zip(en_sentence, hing_sentence):\n    yield en\n    yield hi\nmax_len = 500\nvocab_size = 20_000\n\nnmt_tokenizer_model = tokenizers.models.BPE(unk_token=\"<unk>\")\nnmt_tokenizer = tokenizers.Tokenizer(nmt_tokenizer_model)\nnmt_tokenizer.enable_padding(pad_id=0, pad_token=\"<pad>\")\nnmt_tokenizer.enable_truncation(max_length=max_len)\nnmt_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Whitespace()\nnmt_tokenizer_trainer = tokenizers.trainers.BpeTrainer(\n    vocab_size=vocab_size, special_tokens=[\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"])\nnmt_tokenizer.train_from_iterator(train_eng_hing(), nmt_tokenizer_trainer)\n","metadata":{"id":"d-PnnkG7s2Ri","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:24.261199Z","iopub.execute_input":"2025-09-21T08:02:24.261422Z","iopub.status.idle":"2025-09-21T08:02:26.899049Z","shell.execute_reply.started":"2025-09-21T08:02:24.261405Z","shell.execute_reply":"2025-09-21T08:02:26.898314Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"nmt_tokenizer.encode(\"I love football\").ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1--CKM401n0","outputId":"5e5e103d-bfa1-42ad-eff5-e7db872ecd4c","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:26.899755Z","iopub.execute_input":"2025-09-21T08:02:26.900019Z","iopub.status.idle":"2025-09-21T08:02:26.905118Z","shell.execute_reply.started":"2025-09-21T08:02:26.899949Z","shell.execute_reply":"2025-09-21T08:02:26.904480Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[44, 1251, 2277]"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"nmt_tokenizer.encode(\"Muje football pasand hai.\").ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFKDeUSH0-KI","outputId":"cf28a3fc-a799-4c25-d183-fa429fc1749a","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:26.905816Z","iopub.execute_input":"2025-09-21T08:02:26.906327Z","iopub.status.idle":"2025-09-21T08:02:26.920485Z","shell.execute_reply.started":"2025-09-21T08:02:26.906303Z","shell.execute_reply":"2025-09-21T08:02:26.919919Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[758, 2277, 1852, 349, 17]"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from collections import namedtuple\n\nfields = [\"src_token_ids\", \"src_mask\", \"tgt_token_ids\", \"tgt_mask\"]\nclass NMTPair(namedtuple(\"NmtPairBase\", fields)):\n  def to(self,device):\n    return NMTPair(\n        self.src_token_ids.to(device),\n        self.src_mask.to(device),\n        self.tgt_token_ids.to(device),\n        self.tgt_mask.to(device)\n    )","metadata":{"id":"neKaiftH8kFh","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:26.921126Z","iopub.execute_input":"2025-09-21T08:02:26.921327Z","iopub.status.idle":"2025-09-21T08:02:26.934793Z","shell.execute_reply.started":"2025-09-21T08:02:26.921303Z","shell.execute_reply":"2025-09-21T08:02:26.934053Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def nmt_collate_fn(batch):\n  src_text = [item[\"English\"] for item in batch]\n  tgt_text = [f\"<s> {item['Hinglish']} </s>\" for item in batch]\n  src_encodings = nmt_tokenizer.encode_batch(src_text)\n  tgt_encodings = nmt_tokenizer.encode_batch(tgt_text)\n  src_token_ids = torch.tensor([enc.ids for enc in src_encodings])\n  tgt_token_ids = torch.tensor([enc.ids for enc in tgt_encodings])\n  src_mask = torch.tensor([enc.attention_mask for enc in src_encodings])\n  tgt_mask = torch.tensor([enc.attention_mask for enc in tgt_encodings])\n  inputs = NMTPair(src_token_ids,\n                  src_mask,\n                  tgt_token_ids[:,:-1],\n                  tgt_mask[:,:-1])\n  labels =tgt_token_ids[:,1:]\n  return inputs, labels","metadata":{"id":"uwYI8iJD-I1w","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:26.935500Z","iopub.execute_input":"2025-09-21T08:02:26.935791Z","iopub.status.idle":"2025-09-21T08:02:26.952549Z","shell.execute_reply.started":"2025-09-21T08:02:26.935766Z","shell.execute_reply":"2025-09-21T08:02:26.951856Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"train_set = df.to_dict(\"records\")[:int(0.8 * len(df))]\nvalid_set = df.to_dict(\"records\")[int(0.8 * len(df)):]\ntrain_set[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5dXHpacBgpy","outputId":"004048ec-0680-4e2b-b007-672550684649","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:26.953343Z","iopub.execute_input":"2025-09-21T08:02:26.953648Z","iopub.status.idle":"2025-09-21T08:02:27.803781Z","shell.execute_reply.started":"2025-09-21T08:02:26.953594Z","shell.execute_reply":"2025-09-21T08:02:27.803067Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'English': 'Does it look like we are headed for a thunderstorm ?',\n 'Hinglish': 'kya ye lagta hai ki hum thunderstorm ke jaa rahe hai ?'}"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 126\n\ntrain_loader = DataLoader(\n    train_set,\n    batch_size=batch_size,\n    collate_fn=nmt_collate_fn,\n    shuffle=True\n)\nvalid_loader =DataLoader(\n    valid_set,\n    batch_size=batch_size,\n    collate_fn=nmt_collate_fn\n)","metadata":{"id":"FdtHPNhfBynU","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:27.805925Z","iopub.execute_input":"2025-09-21T08:02:27.806331Z","iopub.status.idle":"2025-09-21T08:02:27.810449Z","shell.execute_reply.started":"2025-09-21T08:02:27.806312Z","shell.execute_reply":"2025-09-21T08:02:27.809807Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nclass NmtModel(nn.Module):\n  def __init__(self, vocab_size, embed_size=512, hidden_size=512, pad_id=0, n_layers=2):\n    super().__init__()\n    self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=pad_id)\n    self.encoder = nn.GRU(embed_size, hidden_size, num_layers=n_layers,\n                          batch_first=True,bidirectional=True)\n    self.decoder = nn.GRU(embed_size, hidden_size*2, num_layers=n_layers,\n                          batch_first=True)\n    self.output = nn.Linear(hidden_size*2, vocab_size)\n\n  def forward(self, pair):\n    #Embeddings\n    src_embeddings = self.embed(pair.src_token_ids)\n    tgt_embeddings = self.embed(pair.tgt_token_ids)\n\n    #Encoder\n    src_lengths = pair.src_mask.sum(dim=1)\n    encoder_packed = pack_padded_sequence(\n        src_embeddings,\n        lengths=src_lengths.cpu(),\n        batch_first=True,\n        enforce_sorted=False\n    )\n    _, hidden_states = self.encoder(encoder_packed)\n    # Reshape hidden for bidirectional\n    # hidden shape: (num_layers*2, batch, hidden_size)\n    batch_size = hidden_states.size(1)\n    n_layers = hidden_states.size(0) // 2\n    hidden_states = hidden_states.view(n_layers, 2, batch_size, -1)\n    hidden_states = torch.cat([hidden_states[:,0,:,:], hidden_states[:,1,:,:]], dim=2)# shape: (num_layers, batch, hidden*2)\n\n    #Decoder\n    tgt_lengths = pair.tgt_mask.sum(dim=1)\n    decoder_packed = pack_padded_sequence(\n        tgt_embeddings,\n        lengths=tgt_lengths.cpu(),\n        batch_first=True,\n        enforce_sorted=False\n    )\n    outputs, _ = self.decoder(decoder_packed, hidden_states)\n    decoder_outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n      \n    # Output\n    logits = self.output(decoder_outputs)\n    return logits.permute(0, 2, 1)\n","metadata":{"id":"H9uWgEtdDPXy","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:27.811139Z","iopub.execute_input":"2025-09-21T08:02:27.811360Z","iopub.status.idle":"2025-09-21T08:02:27.825328Z","shell.execute_reply.started":"2025-09-21T08:02:27.811343Z","shell.execute_reply":"2025-09-21T08:02:27.824614Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import torchmetrics\n\ndef evaluate_tm(model, data_loader, metric, vocab_size):\n    model.eval()\n    metric.reset()\n    with torch.no_grad():\n        for batch in data_loader:\n            inputs, labels = batch\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            y_pred = model(inputs)\n            metric.update(y_pred.reshape(-1,vocab_size), labels.reshape(-1))\n    return metric.compute()\n\ndef train(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs, vocab_size):\n    history = {\"train_losses\":[],\"train_metrics\":[],\"valid_metrics\":[]}\n    for epoch in range(n_epochs):\n        print(f\"Epoch: {epoch+1}/{n_epochs}\")\n        total_loss = 0\n        metric.reset()\n        model.train()\n        for idx, batch in enumerate(train_loader):\n            inputs, labels = batch\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            y_pred = model(inputs)\n            loss = criterion(y_pred.reshape(-1,vocab_size), labels.reshape(-1))\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            metric.update(y_pred.reshape(-1,vocab_size), labels.reshape(-1))\n            print(f\"\\rBatch {idx+1}/{len(train_loader)}\", end=\"\")\n            print(f\", loss ={total_loss/(idx+1 ):.4f} \", end=\"\")\n        mean_loss = total_loss / len(train_loader)\n        history[\"train_losses\"].append(mean_loss)\n        history[\"train_metrics\"].append(metric.compute().item())\n        val_metric = evaluate_tm(model, valid_loader, metric,vocab_size).item()\n        history[\"valid_metrics\"].append(val_metric)\n        print(f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n             f\"Train Metric: {history['train_metrics'][-1]:.4f}%, \"\n             f\"Valid Metric: {history['valid_metrics'][-1]:.4f}%\")\n    return history","metadata":{"id":"xe_d69pQHF0A","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:27.826198Z","iopub.execute_input":"2025-09-21T08:02:27.826453Z","iopub.status.idle":"2025-09-21T08:02:27.843274Z","shell.execute_reply.started":"2025-09-21T08:02:27.826436Z","shell.execute_reply":"2025-09-21T08:02:27.842540Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"nmt_model = NmtModel(vocab_size).to(device)\n\nn_epochs = 20\nxentropy = nn.CrossEntropyLoss(ignore_index=0)\naccuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocab_size).to(device)\noptimizer = torch.optim.NAdam(nmt_model.parameters())\n\nhistory = train(nmt_model, optimizer, xentropy, accuracy, train_loader, valid_loader,\n                n_epochs,vocab_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"id":"c0YHMZrRGo7U","outputId":"6ab57c5b-3347-4654-8cc0-6ff6ccf0bea9","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:02:27.844116Z","iopub.execute_input":"2025-09-21T08:02:27.844302Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1/20\nBatch 358/1201, loss =9.6920 ","output_type":"stream"}],"execution_count":null}]}