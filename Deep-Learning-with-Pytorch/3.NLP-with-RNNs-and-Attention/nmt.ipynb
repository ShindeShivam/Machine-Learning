{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13123799,"sourceType":"datasetVersion","datasetId":8313502}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport json","metadata":{"id":"RunX_vFqQaRn","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:27.012749Z","iopub.execute_input":"2025-09-21T08:09:27.013003Z","iopub.status.idle":"2025-09-21T08:09:31.459554Z","shell.execute_reply.started":"2025-09-21T08:09:27.012980Z","shell.execute_reply":"2025-09-21T08:09:31.458718Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\n    print(torch.cuda.device_count())\nelif torch.backends.mps.is_available():\n    device = \"mps\"\nelse:\n    device = \"cpu\"\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"V8glhYZZVUy7","outputId":"fc2fd6d1-680c-420f-d2f0-f1ad6bcb6ed2","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:31.460371Z","iopub.execute_input":"2025-09-21T08:09:31.460775Z","iopub.status.idle":"2025-09-21T08:09:31.551651Z","shell.execute_reply.started":"2025-09-21T08:09:31.460749Z","shell.execute_reply":"2025-09-21T08:09:31.550890Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"## Data Loading","metadata":{"id":"doavUtPbVrot"}},{"cell_type":"code","source":"data = []\nfilename = \"/kaggle/input/english-hinglish-text/hinglish_upload_v1.json\"\n\nwith open(filename, \"r\", encoding=\"utf-8\") as f:\n  for line in f:\n    obj = json.loads(line)\n    data.append({\n        \"English\":obj[\"translation\"][\"en\"],\n        \"Hinglish\":obj[\"translation\"][\"hi_ng\"]\n    })\n","metadata":{"id":"L654n9RxRkla","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:31.553383Z","iopub.execute_input":"2025-09-21T08:09:31.553595Z","iopub.status.idle":"2025-09-21T08:09:32.300877Z","shell.execute_reply.started":"2025-09-21T08:09:31.553579Z","shell.execute_reply":"2025-09-21T08:09:32.300218Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.DataFrame(data)\ndf = df.sample(frac=1).reset_index(drop=True)\n\ndef preprocess_text(text):\n  return str(text).strip()\n\nen_sentence = df[\"English\"].apply(preprocess_text).tolist()\nhing_sentence = df[\"Hinglish\"].apply(preprocess_text).tolist()\n\nfor i in range(3):\n    print(en_sentence[i], \"=>\", hing_sentence[i])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6jBbQButTO3j","outputId":"bf9d6030-01ef-44d3-debf-6b9e020e4a6a","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:32.301629Z","iopub.execute_input":"2025-09-21T08:09:32.301903Z","iopub.status.idle":"2025-09-21T08:09:32.580989Z","shell.execute_reply.started":"2025-09-21T08:09:32.301879Z","shell.execute_reply":"2025-09-21T08:09:32.580369Z"}},"outputs":[{"name":"stdout","text":"Tell me the five - day forecast => Muje panch - din ka forecast bataiye\nShall I bring umbrella today ? => Kya muje aaj umbrella lana chahiye ?\nIt is a well written comedy, have you seen it? => bahut hi achchi tarah se likhi gayi comedy hai, tumne dhekhi hai kya?\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Tokenization","metadata":{"id":"27DEv6xvVy00"}},{"cell_type":"code","source":"import tokenizers\ndef train_eng_hing():\n  for en, hi in zip(en_sentence, hing_sentence):\n    yield en\n    yield hi\nmax_len = 500\nvocab_size = 20_000\n\nnmt_tokenizer_model = tokenizers.models.BPE(unk_token=\"<unk>\")\nnmt_tokenizer = tokenizers.Tokenizer(nmt_tokenizer_model)\nnmt_tokenizer.enable_padding(pad_id=0, pad_token=\"<pad>\")\nnmt_tokenizer.enable_truncation(max_length=max_len)\nnmt_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Whitespace()\nnmt_tokenizer_trainer = tokenizers.trainers.BpeTrainer(\n    vocab_size=vocab_size, special_tokens=[\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"])\nnmt_tokenizer.train_from_iterator(train_eng_hing(), nmt_tokenizer_trainer)\n","metadata":{"id":"d-PnnkG7s2Ri","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:32.581641Z","iopub.execute_input":"2025-09-21T08:09:32.581840Z","iopub.status.idle":"2025-09-21T08:09:35.436278Z","shell.execute_reply.started":"2025-09-21T08:09:32.581825Z","shell.execute_reply":"2025-09-21T08:09:35.435607Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"nmt_tokenizer.encode(\"I love football\").ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1--CKM401n0","outputId":"5e5e103d-bfa1-42ad-eff5-e7db872ecd4c","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:35.436982Z","iopub.execute_input":"2025-09-21T08:09:35.437222Z","iopub.status.idle":"2025-09-21T08:09:35.442287Z","shell.execute_reply.started":"2025-09-21T08:09:35.437200Z","shell.execute_reply":"2025-09-21T08:09:35.441567Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[44, 1251, 2277]"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"nmt_tokenizer.encode(\"Muje football pasand hai.\").ids","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFKDeUSH0-KI","outputId":"cf28a3fc-a799-4c25-d183-fa429fc1749a","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:35.443075Z","iopub.execute_input":"2025-09-21T08:09:35.443276Z","iopub.status.idle":"2025-09-21T08:09:35.458432Z","shell.execute_reply.started":"2025-09-21T08:09:35.443261Z","shell.execute_reply":"2025-09-21T08:09:35.457850Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[758, 2277, 1852, 349, 17]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from collections import namedtuple\n\nfields = [\"src_token_ids\", \"src_mask\", \"tgt_token_ids\", \"tgt_mask\"]\nclass NMTPair(namedtuple(\"NmtPairBase\", fields)):\n  def to(self,device):\n    return NMTPair(\n        self.src_token_ids.to(device),\n        self.src_mask.to(device),\n        self.tgt_token_ids.to(device),\n        self.tgt_mask.to(device)\n    )","metadata":{"id":"neKaiftH8kFh","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:35.460591Z","iopub.execute_input":"2025-09-21T08:09:35.461114Z","iopub.status.idle":"2025-09-21T08:09:35.473563Z","shell.execute_reply.started":"2025-09-21T08:09:35.461097Z","shell.execute_reply":"2025-09-21T08:09:35.473057Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def nmt_collate_fn(batch):\n  src_text = [item[\"English\"] for item in batch]\n  tgt_text = [f\"<s> {item['Hinglish']} </s>\" for item in batch]\n  src_encodings = nmt_tokenizer.encode_batch(src_text)\n  tgt_encodings = nmt_tokenizer.encode_batch(tgt_text)\n  src_token_ids = torch.tensor([enc.ids for enc in src_encodings])\n  tgt_token_ids = torch.tensor([enc.ids for enc in tgt_encodings])\n  src_mask = torch.tensor([enc.attention_mask for enc in src_encodings])\n  tgt_mask = torch.tensor([enc.attention_mask for enc in tgt_encodings])\n  inputs = NMTPair(src_token_ids,\n                  src_mask,\n                  tgt_token_ids[:,:-1],\n                  tgt_mask[:,:-1])\n  labels =tgt_token_ids[:,1:]\n  return inputs, labels","metadata":{"id":"uwYI8iJD-I1w","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:35.474193Z","iopub.execute_input":"2025-09-21T08:09:35.474350Z","iopub.status.idle":"2025-09-21T08:09:35.489701Z","shell.execute_reply.started":"2025-09-21T08:09:35.474337Z","shell.execute_reply":"2025-09-21T08:09:35.489000Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_set = df.to_dict(\"records\")[:int(0.8 * len(df))]\nvalid_set = df.to_dict(\"records\")[int(0.8 * len(df)):]\ntrain_set[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5dXHpacBgpy","outputId":"004048ec-0680-4e2b-b007-672550684649","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:35.490446Z","iopub.execute_input":"2025-09-21T08:09:35.490652Z","iopub.status.idle":"2025-09-21T08:09:36.334300Z","shell.execute_reply.started":"2025-09-21T08:09:35.490630Z","shell.execute_reply":"2025-09-21T08:09:36.333719Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'English': 'Tell me the five - day forecast',\n 'Hinglish': 'Muje panch - din ka forecast bataiye'}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 64\n\ntrain_loader = DataLoader(\n    train_set,\n    batch_size=batch_size,\n    collate_fn=nmt_collate_fn,\n    shuffle=True\n)\nvalid_loader =DataLoader(\n    valid_set,\n    batch_size=batch_size,\n    collate_fn=nmt_collate_fn\n)","metadata":{"id":"FdtHPNhfBynU","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:36.334973Z","iopub.execute_input":"2025-09-21T08:09:36.335230Z","iopub.status.idle":"2025-09-21T08:09:36.339526Z","shell.execute_reply.started":"2025-09-21T08:09:36.335213Z","shell.execute_reply":"2025-09-21T08:09:36.338875Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nclass NmtModel(nn.Module):\n  def __init__(self, vocab_size, embed_size=512, hidden_size=512, pad_id=0, n_layers=2):\n    super().__init__()\n    self.embed = nn.Embedding(vocab_size, embed_size, padding_idx=pad_id)\n    self.encoder = nn.GRU(embed_size, hidden_size, num_layers=n_layers,\n                          batch_first=True,bidirectional=True)\n    self.decoder = nn.GRU(embed_size, hidden_size*2, num_layers=n_layers,\n                          batch_first=True)\n    self.output = nn.Linear(hidden_size*2, vocab_size)\n\n  def forward(self, pair):\n    #Embeddings\n    src_embeddings = self.embed(pair.src_token_ids)\n    tgt_embeddings = self.embed(pair.tgt_token_ids)\n\n    #Encoder\n    src_lengths = pair.src_mask.sum(dim=1)\n    encoder_packed = pack_padded_sequence(\n        src_embeddings,\n        lengths=src_lengths.cpu(),\n        batch_first=True,\n        enforce_sorted=False\n    )\n    _, hidden_states = self.encoder(encoder_packed)\n    # Reshape hidden for bidirectional\n    # hidden shape: (num_layers*2, batch, hidden_size)\n    batch_size = hidden_states.size(1)\n    n_layers = hidden_states.size(0) // 2\n    hidden_states = hidden_states.view(n_layers, 2, batch_size, -1)\n    hidden_states = torch.cat([hidden_states[:,0,:,:], hidden_states[:,1,:,:]], dim=2)# shape: (num_layers, batch, hidden*2)\n\n    #Decoder\n    tgt_lengths = pair.tgt_mask.sum(dim=1)\n    decoder_packed = pack_padded_sequence(\n        tgt_embeddings,\n        lengths=tgt_lengths.cpu(),\n        batch_first=True,\n        enforce_sorted=False\n    )\n    outputs, _ = self.decoder(decoder_packed, hidden_states)\n    decoder_outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n      \n    # Output\n    logits = self.output(decoder_outputs)\n    return logits.permute(0, 2, 1)\n","metadata":{"id":"H9uWgEtdDPXy","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:09:36.340264Z","iopub.execute_input":"2025-09-21T08:09:36.340442Z","iopub.status.idle":"2025-09-21T08:09:36.357512Z","shell.execute_reply.started":"2025-09-21T08:09:36.340426Z","shell.execute_reply":"2025-09-21T08:09:36.356777Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import torchmetrics\n\ndef evaluate_tm(model, data_loader, metric):\n    model.eval()\n    metric.reset()\n    with torch.no_grad():\n        for X_batch, y_batch in data_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred = model(X_batch)\n            metric.update(y_pred, y_batch)\n    return metric.compute()\n\ndef train(model, optimizer, criterion, metric, train_loader, valid_loader, n_epochs):\n    history = {\"train_losses\":[],\"train_metrics\":[],\"valid_metrics\":[]}\n    for epoch in range(n_epochs):\n        print(f\"Epoch: {epoch+1}/{n_epochs}\", end=\"\")\n        total_loss = 0\n        metric.reset()\n        model.train()\n        for idx, (X_batch, y_batch) in enumerate(train_loader):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred = model(X_batch)\n            loss = criterion(y_pred, y_batch)\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            metric.update(y_pred, y_batch)\n            print(f\"\\rBatch {idx+1}/{len(train_loader)}\", end=\"\")\n            print(f\", loss ={total_loss/(idx+1 ):.4f} \", end=\"\")\n        mean_loss = total_loss / len(train_loader)\n        history[\"train_losses\"].append(mean_loss)\n        history[\"train_metrics\"].append(metric.compute().item())\n        val_metric = evaluate_tm(model, valid_loader, metric).item()\n        history[\"valid_metrics\"].append(val_metric)\n        print(f\"Train Loss: {history['train_losses'][-1]:.4f}, \"\n             f\"Train Metric: {history['train_metrics'][-1]:.4f}%, \"\n             f\"Valid Metric: {history['valid_metrics'][-1]:.4f}%\")\n    return history","metadata":{"id":"xe_d69pQHF0A","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:19:02.229386Z","iopub.execute_input":"2025-09-21T08:19:02.229950Z","iopub.status.idle":"2025-09-21T08:19:02.237479Z","shell.execute_reply.started":"2025-09-21T08:19:02.229927Z","shell.execute_reply":"2025-09-21T08:19:02.236643Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"nmt_model = NmtModel(vocab_size).to(device)\n\nn_epochs = 20\nxentropy = nn.CrossEntropyLoss(ignore_index=0)\naccuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocab_size).to(device)\noptimizer = torch.optim.AdamW(nmt_model.parameters(), lr=5e-4, weight_decay=1e-2)\n\nhistory = train(nmt_model, optimizer, xentropy, accuracy, train_loader, valid_loader,n_epochs)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"id":"c0YHMZrRGo7U","outputId":"6ab57c5b-3347-4654-8cc0-6ff6ccf0bea9","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:19:04.704025Z","iopub.execute_input":"2025-09-21T08:19:04.704309Z","iopub.status.idle":"2025-09-21T09:47:24.637870Z","shell.execute_reply.started":"2025-09-21T08:19:04.704287Z","shell.execute_reply":"2025-09-21T09:47:24.637096Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1/20\nBatch 2364/2364, loss =2.7303 Train Loss: 2.7303, Train Metric: 0.1608%, Valid Metric: 0.1901%\nEpoch: 2/20\nBatch 2364/2364, loss =1.5441 Train Loss: 1.5441, Train Metric: 0.2024%, Valid Metric: 0.2013%\nEpoch: 3/20\nBatch 2364/2364, loss =0.9971 Train Loss: 0.9971, Train Metric: 0.2251%, Valid Metric: 0.2049%\nEpoch: 4/20\nBatch 2364/2364, loss =0.6442 Train Loss: 0.6442, Train Metric: 0.2444%, Valid Metric: 0.2060%\nEpoch: 5/20\nBatch 2364/2364, loss =0.4300 Train Loss: 0.4300, Train Metric: 0.2586%, Valid Metric: 0.2058%\nEpoch: 6/20\nBatch 2364/2364, loss =0.2986 Train Loss: 0.2986, Train Metric: 0.2672%, Valid Metric: 0.2056%\nEpoch: 7/20\nBatch 2364/2364, loss =0.2218 Train Loss: 0.2218, Train Metric: 0.2728%, Valid Metric: 0.2053%\nEpoch: 8/20\nBatch 2364/2364, loss =0.1797 Train Loss: 0.1797, Train Metric: 0.2745%, Valid Metric: 0.2053%\nEpoch: 9/20\nBatch 2364/2364, loss =0.1576 Train Loss: 0.1576, Train Metric: 0.2760%, Valid Metric: 0.2053%\nEpoch: 10/20\nBatch 2364/2364, loss =0.1418 Train Loss: 0.1418, Train Metric: 0.2774%, Valid Metric: 0.2049%\nEpoch: 11/20\nBatch 2364/2364, loss =0.1303 Train Loss: 0.1303, Train Metric: 0.2779%, Valid Metric: 0.2047%\nEpoch: 12/20\nBatch 2364/2364, loss =0.1236 Train Loss: 0.1236, Train Metric: 0.2781%, Valid Metric: 0.2045%\nEpoch: 13/20\nBatch 2364/2364, loss =0.1197 Train Loss: 0.1197, Train Metric: 0.2799%, Valid Metric: 0.2043%\nEpoch: 14/20\nBatch 2364/2364, loss =0.1146 Train Loss: 0.1146, Train Metric: 0.2802%, Valid Metric: 0.2042%\nEpoch: 15/20\nBatch 2364/2364, loss =0.1088 Train Loss: 0.1088, Train Metric: 0.2805%, Valid Metric: 0.2046%\nEpoch: 16/20\nBatch 2364/2364, loss =0.1083 Train Loss: 0.1083, Train Metric: 0.2787%, Valid Metric: 0.2042%\nEpoch: 17/20\nBatch 2364/2364, loss =0.1075 Train Loss: 0.1075, Train Metric: 0.2812%, Valid Metric: 0.2043%\nEpoch: 18/20\nBatch 2364/2364, loss =0.1026 Train Loss: 0.1026, Train Metric: 0.2808%, Valid Metric: 0.2040%\nEpoch: 19/20\nBatch 2364/2364, loss =0.1039 Train Loss: 0.1039, Train Metric: 0.2812%, Valid Metric: 0.2044%\nEpoch: 20/20\nBatch 2364/2364, loss =0.1005 Train Loss: 0.1005, Train Metric: 0.2798%, Valid Metric: 0.2041%\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"nmt_tokenizer.id_to_token(2277)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:48:30.904312Z","iopub.execute_input":"2025-09-21T09:48:30.904597Z","iopub.status.idle":"2025-09-21T09:48:30.909272Z","shell.execute_reply.started":"2025-09-21T09:48:30.904578Z","shell.execute_reply":"2025-09-21T09:48:30.908717Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'football'"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def translate(model, src_text, max_len=20, eos_id=3):\n    tgt_text = \"\"\n    for idx in range(max_len):\n        batch, _ = nmt_collate_fn([{\"English\":src_text ,\n                                   \"Hinglish\":tgt_text}])\n        with torch.no_grad():\n            y_pred = model(batch.to(device))\n            y_token_ids = y_pred.argmax(dim=1)\n            next_token_ids = y_token_ids[0, idx]\n        next_token = nmt_tokenizer.id_to_token(next_token_ids)\n        tgt_text += \" \" + next_token\n        if next_token == eos_id:\n            break\n    return tgt_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:49:19.844824Z","iopub.execute_input":"2025-09-21T09:49:19.845526Z","iopub.status.idle":"2025-09-21T09:49:19.850012Z","shell.execute_reply.started":"2025-09-21T09:49:19.845501Z","shell.execute_reply":"2025-09-21T09:49:19.849294Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"translate(nmt_model,\"hello world\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:51:24.749174Z","iopub.execute_input":"2025-09-21T09:51:24.749727Z","iopub.status.idle":"2025-09-21T09:51:24.814398Z","shell.execute_reply.started":"2025-09-21T09:51:24.749704Z","shell.execute_reply":"2025-09-21T09:51:24.813835Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"' hello </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> dwara </s> </s> </s>'"},"metadata":{}}],"execution_count":38}]}