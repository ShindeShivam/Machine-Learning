{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2f721a8-cc83-4439-856a-c11013ce9ec8",
      "metadata": {
        "id": "f2f721a8-cc83-4439-856a-c11013ce9ec8"
      },
      "source": [
        "# Generating Shakespearean Text Using a Character RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54811d95-83c6-4c8e-92f8-53926c3c19ac",
      "metadata": {
        "id": "54811d95-83c6-4c8e-92f8-53926c3c19ac"
      },
      "source": [
        "### Creating the Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ycn4_cYqqcOh"
      },
      "id": "Ycn4_cYqqcOh",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"GPU connected successfully!\")\n",
        "else:\n",
        "  print(\"No GPU detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLJ5J6m9qZtV",
        "outputId": "3b579c73-f0a7-4620-f69b-475d67e06c63"
      },
      "id": "aLJ5J6m9qZtV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU connected successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8f9c7b9d-8e3a-4c80-9154-904d67a75c74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f9c7b9d-8e3a-4c80-9154-904d67a75c74",
        "outputId": "deb6b87d-4de2-48e5-fb62-5a4876c3cacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath =  tf.keras.utils.get_file(\"shakespeare.txt\",shakespeare_url)\n",
        "\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c0724536-515e-46d7-a5fd-dab09555162b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0724536-515e-46d7-a5fd-dab09555162b",
        "outputId": "ea43218f-60e3-4b43-a8b6-8e547d8d9f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "293cb777-c588-4ce2-bb84-37145d5295b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "293cb777-c588-4ce2-bb84-37145d5295b7",
        "outputId": "3912525f-5ce4-44cb-9d45-3cc9195a8cf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\"\".join(sorted(set(shakespeare_text.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ccb1ccec-2659-4245-b469-3afc12135947",
      "metadata": {
        "id": "ccb1ccec-2659-4245-b469-3afc12135947"
      },
      "outputs": [],
      "source": [
        "text_vector_layer=tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vector_layer.adapt([shakespeare_text])\n",
        "encoded = text_vector_layer([shakespeare_text])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dff79a06-6eb7-4a52-930f-7e51634fccb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dff79a06-6eb7-4a52-930f-7e51634fccb5",
        "outputId": "e800da84-ed34-4b01-c6bb-309363ff7492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', np.str_(' '), np.str_('e'), np.str_('t'), np.str_('o'), np.str_('a'), np.str_('i'), np.str_('h'), np.str_('s'), np.str_('r'), np.str_('n'), np.str_('\\n'), np.str_('l'), np.str_('d'), np.str_('u'), np.str_('m'), np.str_('y'), np.str_('w'), np.str_(','), np.str_('c'), np.str_('f'), np.str_('g'), np.str_('b'), np.str_('p'), np.str_(':'), np.str_('k'), np.str_('v'), np.str_('.'), np.str_(\"'\"), np.str_(';'), np.str_('?'), np.str_('!'), np.str_('-'), np.str_('j'), np.str_('q'), np.str_('x'), np.str_('z'), np.str_('3'), np.str_('&'), np.str_('$')]\n"
          ]
        }
      ],
      "source": [
        "print(text_vector_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bcb9595f-303f-4f9b-8cf0-a13f8168ad5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb9595f-303f-4f9b-8cf0-a13f8168ad5d",
        "outputId": "131247f9-40a0-4a62-df39-105a5b06b9ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(text_vector_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a66cebd1-5f43-49ab-9ce7-940521cd1212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a66cebd1-5f43-49ab-9ce7-940521cd1212",
        "outputId": "ef3177f7-61ed-4c94-ee81-5d4cd0fbf037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a2f50642-b8b5-4ab6-8413-86af964d03d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2f50642-b8b5-4ab6-8413-86af964d03d7",
        "outputId": "d09fa83c-1ae2-4282-9d23-8268ec1f7479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "068b4ac8-c6e7-42e9-accb-e79a63fa88b7",
      "metadata": {
        "id": "068b4ac8-c6e7-42e9-accb-e79a63fa88b7"
      },
      "outputs": [],
      "source": [
        "encoded-=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "325fb4e1-99ce-42c6-86a4-6526d96acb49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "325fb4e1-99ce-42c6-86a4-6526d96acb49",
        "outputId": "36c8fe38-ecfa-4a19-fa4d-0456c5c39c2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19,  5,  8, ..., 20, 26, 10])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b74e0a49-1702-4118-a1af-0d762b0c0850",
      "metadata": {
        "id": "b74e0a49-1702-4118-a1af-0d762b0c0850"
      },
      "outputs": [],
      "source": [
        "n_tokens = text_vector_layer.vocabulary_size()-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ecbca507-ae9e-49b1-b00d-55e6abc56b2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecbca507-ae9e-49b1-b00d-55e6abc56b2d",
        "outputId": "3e9d1b9a-33ad-4f15-d79c-8552d0351059"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "n_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "431439cd-1ec7-4b56-a6db-3e836cb698b4",
      "metadata": {
        "id": "431439cd-1ec7-4b56-a6db-3e836cb698b4"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDatasetBuilder:\n",
        "    def __init__(self,series,window_size=56,target_columns=None,horizon=1,seq_to_seq=False,\n",
        "                 batch_size=32,buffer_size=10_000,shuffle=True,seed=42):\n",
        "        self.series=np.array(series)\n",
        "        self.window_size=window_size\n",
        "        self.target_columns=target_columns\n",
        "        self.horizon=horizon\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle=shuffle\n",
        "        self.seed=seed\n",
        "        self.seq_to_seq=seq_to_seq\n",
        "        self.buffer_size=buffer_size\n",
        "\n",
        "\n",
        "    def _create_X_y(self):\n",
        "        X,y=[],[]\n",
        "\n",
        "        for i in range(len(self.series) - self.window_size - self.horizon + 1):\n",
        "            window=self.series[i:i+self.window_size]\n",
        "\n",
        "            if self.seq_to_seq:\n",
        "              target_seq=[]\n",
        "              for j in range(self.window_size):\n",
        "                future=self.series[i + j + 1:i + j + 1 + self.horizon]\n",
        "                if self.target_columns is not None:\n",
        "                  future=future[:,self.target_columns]\n",
        "                target_seq.append(future)\n",
        "              target_seq=np.array(target_seq)\n",
        "\n",
        "              y.append(target_seq)\n",
        "            else:\n",
        "              future=self.series[i+self.window_size:i+self.window_size+self.horizon]\n",
        "              if self.target_columns is not None:\n",
        "                future=future[:,self.target_columns]\n",
        "              if self.horizon==1:\n",
        "                future=future[0]\n",
        "              y.append(future)\n",
        "\n",
        "            X.append(window)\n",
        "\n",
        "        return np.array(X),np.array(y)\n",
        "\n",
        "    def get_tf_dataset(self):\n",
        "        X,y=self._create_X_y()\n",
        "        ds=tf.data.Dataset.from_tensor_slices((X,y))\n",
        "        if self.shuffle:\n",
        "            ds=ds.shuffle(buffer_size=self.buffer_size,seed=self.seed)\n",
        "        ds=ds.batch(self.batch_size)\n",
        "        ds=ds.prefetch(tf.data.AUTOTUNE)\n",
        "        return ds\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "16160924-c6eb-4f37-9526-06d392f283a2",
      "metadata": {
        "id": "16160924-c6eb-4f37-9526-06d392f283a2"
      },
      "outputs": [],
      "source": [
        "window_size = 100\n",
        "builder_train=TimeSeriesDatasetBuilder(\n",
        "   series=encoded[:1_000_000],\n",
        "   window_size=window_size,\n",
        "   batch_size=32,\n",
        "   buffer_size=100_000,\n",
        "   seq_to_seq=True\n",
        ")\n",
        "builder_valid=TimeSeriesDatasetBuilder(\n",
        "   series=encoded[1_000_000:1_060_000],\n",
        "   window_size=window_size,\n",
        "   batch_size=32,\n",
        "   buffer_size=10_000,\n",
        "   seq_to_seq=True\n",
        ")\n",
        "builder_test=TimeSeriesDatasetBuilder(\n",
        "   series=encoded[1_060_000:],\n",
        "   window_size=window_size,\n",
        "   batch_size=32,\n",
        "   buffer_size=10_000,\n",
        "   seq_to_seq=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "61c2a71d-f17d-4f60-b6d2-a07ce3c536e1",
      "metadata": {
        "id": "61c2a71d-f17d-4f60-b6d2-a07ce3c536e1"
      },
      "outputs": [],
      "source": [
        "train_set = builder_train.get_tf_dataset()\n",
        "valid_set = builder_valid.get_tf_dataset()\n",
        "test_set = builder_test.get_tf_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "241c1675-f1ba-46e9-89bc-233b80306c3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "241c1675-f1ba-46e9-89bc-233b80306c3a",
        "outputId": "d9b2aed1-2f14-4736-e483-c0131d1aa18f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 39\n",
            "Total encoded length: 1115394\n",
            "Training samples: ~999900\n",
            "Validation samples: ~59900\n",
            "Test samples: ~55294\n",
            "Input batch shape: (32, 100)\n",
            "Target batch shape: (32, 100, 1)\n",
            "Input example (first 10 chars): [ 9 12  0 19  5 20  6  2  0 16]\n",
            "Target example (first 10 predictions): [12  0 19  5 20  6  2  0 16  5]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Vocabulary size: {n_tokens}\")\n",
        "print(f\"Total encoded length: {len(encoded)}\")\n",
        "print(f\"Training samples: ~{len(encoded[:1_000_000]) - window_size}\")\n",
        "print(f\"Validation samples: ~{60_000 - window_size}\")\n",
        "print(f\"Test samples: ~{len(encoded[1_060_000:]) - window_size}\")\n",
        "\n",
        "for batch_x, batch_y in train_set.take(1):\n",
        "    print(f\"Input batch shape: {batch_x.shape}\")\n",
        "    print(f\"Target batch shape: {batch_y.shape}\")\n",
        "    print(f\"Input example (first 10 chars): {batch_x[0][:10].numpy()}\")\n",
        "    print(f\"Target example (first 10 predictions): {batch_y[0][:10].numpy().flatten()}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training the Char-RNN Model"
      ],
      "metadata": {
        "id": "bm2oDBXNqvY-"
      },
      "id": "bm2oDBXNqvY-"
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens,output_dim=16),\n",
        "    tf.keras.layers.GRU(128,return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens,activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_ckp = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model.keras\",\n",
        "                            monitor=\"val_accuracy\",save_best_only=True)\n",
        "history = model.fit(train_set,\n",
        "                    epochs=10,\n",
        "                    validation_data=(valid_set),\n",
        "                     callbacks=[model_ckp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4HCdX8sqhO2",
        "outputId": "d894a208-c72f-4f5d-e64d-dc104f282a90"
      },
      "id": "Y4HCdX8sqhO2",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 8ms/step - accuracy: 0.5477 - loss: 1.4978 - val_accuracy: 0.5336 - val_loss: 1.6078\n",
            "Epoch 2/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 1.2897 - val_accuracy: 0.5391 - val_loss: 1.5758\n",
            "Epoch 3/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8ms/step - accuracy: 0.6026 - loss: 1.2699 - val_accuracy: 0.5432 - val_loss: 1.5665\n",
            "Epoch 4/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 1.2598 - val_accuracy: 0.5440 - val_loss: 1.5662\n",
            "Epoch 5/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 8ms/step - accuracy: 0.6067 - loss: 1.2530 - val_accuracy: 0.5449 - val_loss: 1.5592\n",
            "Epoch 6/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8ms/step - accuracy: 0.6075 - loss: 1.2489 - val_accuracy: 0.5456 - val_loss: 1.5596\n",
            "Epoch 7/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 1.2452 - val_accuracy: 0.5447 - val_loss: 1.5586\n",
            "Epoch 8/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8ms/step - accuracy: 0.6091 - loss: 1.2423 - val_accuracy: 0.5453 - val_loss: 1.5628\n",
            "Epoch 9/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8ms/step - accuracy: 0.6097 - loss: 1.2395 - val_accuracy: 0.5480 - val_loss: 1.5518\n",
            "Epoch 10/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 1.2377 - val_accuracy: 0.5479 - val_loss: 1.5515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vector_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "YCp6kC418j-x"
      },
      "id": "YCp6kC418j-x",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
        "y_pred = tf.argmax(y_proba)  # choose the most probable character ID\n",
        "text_vector_layer.get_vocabulary()[y_pred + 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "osFKAcCmCfIA",
        "outputId": "0a6858c2-b35b-495e-bdcc-6a8f3834632d"
      },
      "id": "osFKAcCmCfIA",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=['To be or not to b'] (of type <class 'list'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3906042573.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshakespeare_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"To be or not to b\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# choose the most probable character ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext_vector_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=['To be or not to b'] (of type <class 'list'>)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}