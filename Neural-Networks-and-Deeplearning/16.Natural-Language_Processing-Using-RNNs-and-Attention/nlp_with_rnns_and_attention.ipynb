{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2f721a8-cc83-4439-856a-c11013ce9ec8",
      "metadata": {
        "id": "f2f721a8-cc83-4439-856a-c11013ce9ec8"
      },
      "source": [
        "# Generating Shakespearean Text Using a Character RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54811d95-83c6-4c8e-92f8-53926c3c19ac",
      "metadata": {
        "id": "54811d95-83c6-4c8e-92f8-53926c3c19ac"
      },
      "source": [
        "### Creating the Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ycn4_cYqqcOh"
      },
      "id": "Ycn4_cYqqcOh",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"GPU connected successfully!\")\n",
        "else:\n",
        "  print(\"No GPU detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLJ5J6m9qZtV",
        "outputId": "d5b818c8-e7e6-4f29-9d45-10488b13a543"
      },
      "id": "aLJ5J6m9qZtV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU connected successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8f9c7b9d-8e3a-4c80-9154-904d67a75c74",
      "metadata": {
        "id": "8f9c7b9d-8e3a-4c80-9154-904d67a75c74"
      },
      "outputs": [],
      "source": [
        "\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath =  tf.keras.utils.get_file(\"shakespeare.txt\",shakespeare_url)\n",
        "\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c0724536-515e-46d7-a5fd-dab09555162b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0724536-515e-46d7-a5fd-dab09555162b",
        "outputId": "cfe4341a-c1bb-488b-a819-fdb2d2b81fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "293cb777-c588-4ce2-bb84-37145d5295b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "293cb777-c588-4ce2-bb84-37145d5295b7",
        "outputId": "b8dd9300-8397-42bc-e4b2-23bd13377c5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\"\".join(sorted(set(shakespeare_text.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ccb1ccec-2659-4245-b469-3afc12135947",
      "metadata": {
        "id": "ccb1ccec-2659-4245-b469-3afc12135947"
      },
      "outputs": [],
      "source": [
        "text_vector_layer=tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vector_layer.adapt([shakespeare_text])\n",
        "encoded = text_vector_layer([shakespeare_text])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dff79a06-6eb7-4a52-930f-7e51634fccb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dff79a06-6eb7-4a52-930f-7e51634fccb5",
        "outputId": "c1dd32e9-d114-4b51-ec74-b0c562ef6125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', np.str_(' '), np.str_('e'), np.str_('t'), np.str_('o'), np.str_('a'), np.str_('i'), np.str_('h'), np.str_('s'), np.str_('r'), np.str_('n'), np.str_('\\n'), np.str_('l'), np.str_('d'), np.str_('u'), np.str_('m'), np.str_('y'), np.str_('w'), np.str_(','), np.str_('c'), np.str_('f'), np.str_('g'), np.str_('b'), np.str_('p'), np.str_(':'), np.str_('k'), np.str_('v'), np.str_('.'), np.str_(\"'\"), np.str_(';'), np.str_('?'), np.str_('!'), np.str_('-'), np.str_('j'), np.str_('q'), np.str_('x'), np.str_('z'), np.str_('3'), np.str_('&'), np.str_('$')]\n"
          ]
        }
      ],
      "source": [
        "print(text_vector_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bcb9595f-303f-4f9b-8cf0-a13f8168ad5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb9595f-303f-4f9b-8cf0-a13f8168ad5d",
        "outputId": "2622fbba-aab2-4c79-f27d-50342f1e311f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(text_vector_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a66cebd1-5f43-49ab-9ce7-940521cd1212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a66cebd1-5f43-49ab-9ce7-940521cd1212",
        "outputId": "1e46b199-e1b7-43fe-f79f-5f3281e4c9ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a2f50642-b8b5-4ab6-8413-86af964d03d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2f50642-b8b5-4ab6-8413-86af964d03d7",
        "outputId": "b19e8159-3370-4121-8f59-1f5fe036cdf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([21,  7, 10, ..., 22, 28, 12])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "068b4ac8-c6e7-42e9-accb-e79a63fa88b7",
      "metadata": {
        "id": "068b4ac8-c6e7-42e9-accb-e79a63fa88b7"
      },
      "outputs": [],
      "source": [
        "encoded-=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "325fb4e1-99ce-42c6-86a4-6526d96acb49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "325fb4e1-99ce-42c6-86a4-6526d96acb49",
        "outputId": "a6771686-a426-4074-a16b-a3f6b359881a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19,  5,  8, ..., 20, 26, 10])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b74e0a49-1702-4118-a1af-0d762b0c0850",
      "metadata": {
        "id": "b74e0a49-1702-4118-a1af-0d762b0c0850"
      },
      "outputs": [],
      "source": [
        "n_tokens = text_vector_layer.vocabulary_size()-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ecbca507-ae9e-49b1-b00d-55e6abc56b2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecbca507-ae9e-49b1-b00d-55e6abc56b2d",
        "outputId": "91c20f90-4d04-4415-c2ab-550965db2ad8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "n_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "431439cd-1ec7-4b56-a6db-3e836cb698b4",
      "metadata": {
        "id": "431439cd-1ec7-4b56-a6db-3e836cb698b4"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDatasetBuilder:\n",
        "    def __init__(self,series,window_size=56,target_columns=None,horizon=1,seq_to_seq=False,\n",
        "                 batch_size=32,buffer_size=10_000,shuffle=True,seed=42):\n",
        "        self.series=np.array(series)\n",
        "        self.window_size=window_size\n",
        "        self.target_columns=target_columns\n",
        "        self.horizon=horizon\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle=shuffle\n",
        "        self.seed=seed\n",
        "        self.seq_to_seq=seq_to_seq\n",
        "        self.buffer_size=buffer_size\n",
        "\n",
        "\n",
        "    def _create_X_y(self):\n",
        "        X,y=[],[]\n",
        "\n",
        "        for i in range(len(self.series) - self.window_size - self.horizon + 1):\n",
        "            window=self.series[i:i+self.window_size]\n",
        "\n",
        "            if self.seq_to_seq:\n",
        "              target_seq=[]\n",
        "              for j in range(self.window_size):\n",
        "                future=self.series[i + j + 1:i + j + 1 + self.horizon]\n",
        "                if self.target_columns is not None:\n",
        "                  future=future[:,self.target_columns]\n",
        "                target_seq.append(future)\n",
        "              # target_seq=np.array(target_seq)\n",
        "\n",
        "              y.append(target_seq)\n",
        "            else:\n",
        "              future=self.series[i+self.window_size:i+self.window_size+self.horizon]\n",
        "              if self.target_columns is not None:\n",
        "                future=future[:,self.target_columns]\n",
        "              if self.horizon==1:\n",
        "                future=future[0]\n",
        "              y.append(future)\n",
        "\n",
        "            X.append(window)\n",
        "\n",
        "        return np.array(X),np.array(y)\n",
        "\n",
        "    def get_tf_dataset(self):\n",
        "        X,y=self._create_X_y()\n",
        "        ds=tf.data.Dataset.from_tensor_slices((X,y))\n",
        "        if self.shuffle:\n",
        "            ds=ds.shuffle(buffer_size=self.buffer_size,seed=self.seed)\n",
        "        ds=ds.batch(self.batch_size)\n",
        "        ds=ds.prefetch(tf.data.AUTOTUNE)\n",
        "        return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "16160924-c6eb-4f37-9526-06d392f283a2",
      "metadata": {
        "id": "16160924-c6eb-4f37-9526-06d392f283a2"
      },
      "outputs": [],
      "source": [
        "window_size = 100\n",
        "builder_train=TimeSeriesDatasetBuilder(\n",
        "   series=encoded[:1_000_000],\n",
        "   window_size=window_size,\n",
        "   batch_size=32,\n",
        "   buffer_size=100_000,\n",
        "   seq_to_seq=True\n",
        ")\n",
        "builder_valid=TimeSeriesDatasetBuilder(\n",
        "   series=encoded[1_000_000:1_060_000],\n",
        "   window_size=window_size,\n",
        "   batch_size=32,\n",
        "   buffer_size=10_000,\n",
        "   seq_to_seq=True\n",
        ")\n",
        "builder_test=TimeSeriesDatasetBuilder(\n",
        "   series=encoded[1_060_000:],\n",
        "   window_size=window_size,\n",
        "   batch_size=32,\n",
        "   buffer_size=10_000,\n",
        "   seq_to_seq=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c2a71d-f17d-4f60-b6d2-a07ce3c536e1",
      "metadata": {
        "id": "61c2a71d-f17d-4f60-b6d2-a07ce3c536e1"
      },
      "outputs": [],
      "source": [
        "train_set = builder_train.get_tf_dataset()\n",
        "valid_set = builder_valid.get_tf_dataset()\n",
        "test_set = builder_test.get_tf_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c1675-f1ba-46e9-89bc-233b80306c3a",
      "metadata": {
        "id": "241c1675-f1ba-46e9-89bc-233b80306c3a"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"Vocabulary size: {n_tokens}\")\n",
        "print(f\"Total encoded length: {len(encoded)}\")\n",
        "print(f\"Training samples: ~{len(encoded[:1_000_000]) - window_size}\")\n",
        "print(f\"Validation samples: ~{60_000 - window_size}\")\n",
        "print(f\"Test samples: ~{len(encoded[1_060_000:]) - window_size}\")\n",
        "\n",
        "for batch_x, batch_y in train_set.take(1):\n",
        "    print(f\"Input batch shape: {batch_x.shape}\")\n",
        "    print(f\"Target batch shape: {batch_y.shape}\")\n",
        "    print(f\"Input example (first 10 chars): {batch_x[0][:10].numpy()}\")\n",
        "    print(f\"Target example (first 10 predictions): {batch_y[0][:10].numpy().flatten()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training the Char-RNN Model"
      ],
      "metadata": {
        "id": "bm2oDBXNqvY-"
      },
      "id": "bm2oDBXNqvY-"
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens,output_dim=16),\n",
        "    tf.keras.layers.GRU(128,return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens,activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_ckp = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model.keras\",\n",
        "                            monitor=\"val_accuracy\",save_best_only=True)\n",
        "history = model.fit(train_set,\n",
        "                    epochs=10,\n",
        "                    validation_data=(valid_set),\n",
        "                     callbacks=[model_ckp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4HCdX8sqhO2",
        "outputId": "d894a208-c72f-4f5d-e64d-dc104f282a90"
      },
      "id": "Y4HCdX8sqhO2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 8ms/step - accuracy: 0.5477 - loss: 1.4978 - val_accuracy: 0.5336 - val_loss: 1.6078\n",
            "Epoch 2/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 1.2897 - val_accuracy: 0.5391 - val_loss: 1.5758\n",
            "Epoch 3/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8ms/step - accuracy: 0.6026 - loss: 1.2699 - val_accuracy: 0.5432 - val_loss: 1.5665\n",
            "Epoch 4/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 1.2598 - val_accuracy: 0.5440 - val_loss: 1.5662\n",
            "Epoch 5/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 8ms/step - accuracy: 0.6067 - loss: 1.2530 - val_accuracy: 0.5449 - val_loss: 1.5592\n",
            "Epoch 6/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8ms/step - accuracy: 0.6075 - loss: 1.2489 - val_accuracy: 0.5456 - val_loss: 1.5596\n",
            "Epoch 7/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 1.2452 - val_accuracy: 0.5447 - val_loss: 1.5586\n",
            "Epoch 8/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8ms/step - accuracy: 0.6091 - loss: 1.2423 - val_accuracy: 0.5453 - val_loss: 1.5628\n",
            "Epoch 9/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8ms/step - accuracy: 0.6097 - loss: 1.2395 - val_accuracy: 0.5480 - val_loss: 1.5518\n",
            "Epoch 10/10\n",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 1.2377 - val_accuracy: 0.5479 - val_loss: 1.5515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_model=tf.keras.Sequential([\n",
        "    text_vector_layer,\n",
        "    tf.keras.layers.Lambda(lambda x: x-2),  # no <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "U93hdWFEJk3V"
      },
      "id": "U93hdWFEJk3V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=tf.constant([\"To be or not to be\"])\n",
        "y_proba=shakespeare_model.predict(input_text,verbose=0)[0,-1] # prediction of last character i.e \"b\"\n",
        "y_pred=tf.argmax(y_proba) # most probable character ID\n",
        "text_vector_layer.get_vocabulary()[y_pred+2][0]"
      ],
      "metadata": {
        "id": "jKLFshwbKYJ2",
        "outputId": "d1da929d-4c8f-4e1c-a415-0de4dcc192f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "jKLFshwbKYJ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Fake Shakespearean Text"
      ],
      "metadata": {
        "id": "aX0WJX-_MzPz"
      },
      "id": "aX0WJX-_MzPz"
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = tf.math.log([[0.5,0.4,0.1]])\n",
        "tf.random.categorical(log_probas,num_samples=8)"
      ],
      "metadata": {
        "id": "k1MzA8kIMryg",
        "outputId": "856b1e23-d789-4f0e-a446-d931ceb2a240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k1MzA8kIMryg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 0, 1, 1, 0, 2, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text,temperature=1):\n",
        "  y_proba=shakespeare_model.predict([text],verbose=0)[0,-1:]\n",
        "  rescaled_logits=tf.math.log(y_proba)/temperature\n",
        "  char_id=tf.random.categorical(rescaled_logits,num_samples=1)[0,0]\n",
        "  return text_vector_layer.get_vocabulary()[char_id+2]"
      ],
      "metadata": {
        "id": "EIFA8bBaQr1V"
      },
      "id": "EIFA8bBaQr1V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "def generate_text(text, n_chars=200, temperature=1, delay=0.05):\n",
        "    print(text.numpy()[0].decode(\"utf-8\"), end='', flush=True)  # print the initial prompt\n",
        "\n",
        "    for _ in range(n_chars):\n",
        "        char = next_char(text, temperature)\n",
        "        text += char\n",
        "\n",
        "        print(char, end='', flush=True)\n",
        "        time.sleep(delay)  # typing effect\n",
        "\n"
      ],
      "metadata": {
        "id": "oipkmZajWsMh"
      },
      "id": "oipkmZajWsMh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(input_text, n_chars=500, temperature=0.7, delay=0.0005)\n"
      ],
      "metadata": {
        "id": "yDqJ6nu7blvf",
        "outputId": "0c93436e-6c4f-4d0a-d3be-070b649d17de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yDqJ6nu7blvf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to begin the prince,\n",
            "to fear you but to make the thoral ever boy.\n",
            "\n",
            "pompey:\n",
            "sir, your life, and would not the duke:\n",
            "the desire to make the world.\n",
            "\n",
            "mariana:\n",
            "he shall have an undone finded with our pretty house,\n",
            "and then, let's as it is this delight,\n",
            "and this mind cause to make your grace, if a lady.\n",
            "the prison; for the devittes.\n",
            "\n",
            "duke vincentio:\n",
            "for the time; for i should die to a city.\n",
            "\n",
            "angelo:\n",
            "see, brother-book'd in one leave to see the view\n",
            "by all actions will i unrion, friar, sir, i do not accompon"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stateful RNN"
      ],
      "metadata": {
        "id": "ui5eNE284B0n"
      },
      "id": "ui5eNE284B0n"
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset_for_stateful_rnn(series,window_size):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "  ds = ds.window(window_size+1,shift=window_size,drop_remainder=True)\n",
        "  ds = ds.flat_map(lambda window: window.batch(window_size+1)).batch(1)\n",
        "  return ds.map(lambda window:(window[:,:-1],window[:,1:])).prefetch(1)"
      ],
      "metadata": {
        "id": "_NwD8Fds3xeg"
      },
      "id": "_NwD8Fds3xeg",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000],window_size)\n",
        "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:],window_size)"
      ],
      "metadata": {
        "id": "g1PWVDDW5x-s"
      },
      "id": "g1PWVDDW5x-s",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(batch_shape=[1, None], dtype=tf.int32),\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens,output_dim=16,),\n",
        "    tf.keras.layers.GRU(128,return_sequences=True,stateful=True),\n",
        "    tf.keras.layers.Dense(n_tokens,activation=\"softmax\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "B4n7x_-G6aGw"
      },
      "id": "B4n7x_-G6aGw",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResetStates(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self,epoch,logs):\n",
        "    for layer in self.model.layers:\n",
        "      if hasattr(layer,'reset_states'):\n",
        "        layer.reset_states()"
      ],
      "metadata": {
        "id": "JKJOAwkV6nEK"
      },
      "id": "JKJOAwkV6nEK",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stateful_model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_ckp = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model.keras\",\n",
        "                            monitor=\"val_accuracy\",save_best_only=True)\n",
        "history = stateful_model.fit(stateful_train_set,\n",
        "                    epochs=10,\n",
        "                    validation_data=stateful_valid_set,\n",
        "                     callbacks=[ResetStates(),model_ckp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzrAUdO56mZt",
        "outputId": "f428c259-1475-4a97-be91-6ef7de7810c4"
      },
      "id": "SzrAUdO56mZt",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "   9997/Unknown \u001b[1m83s\u001b[0m 8ms/step - accuracy: 0.3899 - loss: 2.1045"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 9ms/step - accuracy: 0.3899 - loss: 2.1044 - val_accuracy: 0.4778 - val_loss: 1.7421\n",
            "Epoch 2/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 14ms/step - accuracy: 0.5219 - loss: 1.5863 - val_accuracy: 0.5005 - val_loss: 1.6653\n",
            "Epoch 3/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14ms/step - accuracy: 0.5462 - loss: 1.4916 - val_accuracy: 0.5094 - val_loss: 1.6334\n",
            "Epoch 4/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.5574 - loss: 1.4479 - val_accuracy: 0.5163 - val_loss: 1.6162\n",
            "Epoch 5/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14ms/step - accuracy: 0.5642 - loss: 1.4216 - val_accuracy: 0.5196 - val_loss: 1.6101\n",
            "Epoch 6/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.5685 - loss: 1.4046 - val_accuracy: 0.5225 - val_loss: 1.5995\n",
            "Epoch 7/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 14ms/step - accuracy: 0.5718 - loss: 1.3920 - val_accuracy: 0.5230 - val_loss: 1.5967\n",
            "Epoch 8/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.5742 - loss: 1.3827 - val_accuracy: 0.5245 - val_loss: 1.5947\n",
            "Epoch 9/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14ms/step - accuracy: 0.5762 - loss: 1.3756 - val_accuracy: 0.5268 - val_loss: 1.5905\n",
            "Epoch 10/10\n",
            "\u001b[1m9999/9999\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 9ms/step - accuracy: 0.5777 - loss: 1.3698 - val_accuracy: 0.5270 - val_loss: 1.5864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens,output_dim=16),\n",
        "    tf.keras.layers.GRU(128,return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens,activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "IKyZ_T5R_pgN"
      },
      "id": "IKyZ_T5R_pgN",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model.build(tf.TensorShape([None,None]))\n",
        "stateless_model.set_weights(stateful_model.get_weights())"
      ],
      "metadata": {
        "id": "VfRUVt2p_44F"
      },
      "id": "VfRUVt2p_44F",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_model=tf.keras.Sequential([\n",
        "    text_vector_layer,\n",
        "    tf.keras.layers.Lambda(lambda x: x-2),\n",
        "    stateless_model\n",
        "])"
      ],
      "metadata": {
        "id": "95qrVVOmAZ-G"
      },
      "id": "95qrVVOmAZ-G",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text,temperature=1):\n",
        "  y_proba=shakespeare_model.predict([text],verbose=0)[0,-1:]\n",
        "  rescaled_logits=tf.math.log(y_proba)/temperature\n",
        "  char_id=tf.random.categorical(rescaled_logits,num_samples=1)[0,0]\n",
        "  return text_vector_layer.get_vocabulary()[char_id+2]"
      ],
      "metadata": {
        "id": "JRLQjIrVAt0t"
      },
      "id": "JRLQjIrVAt0t",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "def generate_text(text, n_chars=200, temperature=1, delay=0.05):\n",
        "    print(text.numpy()[0].decode(\"utf-8\"), end='', flush=True)  # print the initial prompt\n",
        "\n",
        "    for _ in range(n_chars):\n",
        "        char = next_char(text, temperature)\n",
        "        text += char\n",
        "\n",
        "        print(char, end='', flush=True)\n",
        "        time.sleep(delay)  # typing effect\n"
      ],
      "metadata": {
        "id": "aUnWsJweAxg6"
      },
      "id": "aUnWsJweAxg6",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=tf.constant([\"To be or not to be\"])\n",
        "generate_text(input_text, n_chars=500, temperature=0.7, delay=0.0005)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZac7g5kA1kT",
        "outputId": "c97cd0fd-0f43-4bb4-b24b-dfbe2ca07229"
      },
      "id": "XZac7g5kA1kT",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be\n",
            "with suphock'd it not too more of a life,\n",
            "i'll have you no lion him where is his field.\n",
            "\n",
            "gremio:\n",
            "har to good with her.\n",
            "\n",
            "thire gentleman:\n",
            "trumper, the was a blow you humy me for him:\n",
            "that in my perform'd him and with me her,\n",
            "if bad horse you understand with him with him\n",
            "a wring in horters to know you and here:\n",
            "what i have be have well good and humble us a combinds.\n",
            "\n",
            "duke vincentio:\n",
            "in incrits and babber within the hand,\n",
            "to hear not the trunch a very father,\n",
            "as the state, i will betim this tempes"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}