{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e559655-bd1d-4b20-bfb8-63852779fb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e559a49c-49d0-4fb5-a183-bf71f55db3b1",
   "metadata": {},
   "source": [
    "# The tf.data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6141f7b1-c1c3-4949-afae-2d02774692ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1672e98a-012e-43bf-a133-8650e9024f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.constant([1,2,3,4,5,6,7,8,9])\n",
    "dataset=tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a839f8ea-651b-40ab-bbcd-fddfd4e1c987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851b5f6f-6bfe-4626-ab3d-bfdc96fda960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 13:44:32.061551: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5a055d-b455-40c1-ac0b-2a3114ec5359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=tf.range(10)\n",
    "dataset=tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed00589-f968-4dff-b3b1-37fb4621b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 13:44:32.072384: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b03733-344a-4722-8da1-74486c32d23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=tf.data.Dataset.range(3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99461ca-5a72-40d5-8d72-10b2e924c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'_RangeDataset' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset[3]\n",
    "except TypeError as ex:\n",
    "    print(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06746f5-1825-44df-8c06-5c99252efddf",
   "metadata": {},
   "source": [
    "### tf.data Dataset with Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d10430-a863-4e7e-8a46-2967ee301724",
   "metadata": {},
   "source": [
    "#### Tuple of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c29f61c-9ab4-4a37-9d1b-af926aa9f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "y = tf.constant([0, 1, 0])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e0297f-b1c3-4498-a64e-2f14b425dee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 6], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40949f46-7b98-48f2-89c6-a1da3636fb25",
   "metadata": {},
   "source": [
    "#### Dictionary of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6656e80d-df85-412e-9338-6f28debf5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"feature1\": tf.constant([1.0, 2.0, 3.0]),\n",
    "    \"feature2\": tf.constant([10.0, 20.0, 30.0])\n",
    "}\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df3a415b-84d3-47a7-adf7-f3ea39c3bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature1': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>, 'feature2': <tf.Tensor: shape=(), dtype=float32, numpy=10.0>}\n",
      "{'feature1': <tf.Tensor: shape=(), dtype=float32, numpy=2.0>, 'feature2': <tf.Tensor: shape=(), dtype=float32, numpy=20.0>}\n",
      "{'feature1': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'feature2': <tf.Tensor: shape=(), dtype=float32, numpy=30.0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 13:44:32.122351: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859da1d-15f0-4dd8-b341-3d0445d6694f",
   "metadata": {},
   "source": [
    "####  Nested Tuple + Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcbd1bac-4e81-4fca-8562-eeb653e200ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "y = tf.constant([0, 1, 0])\n",
    "meta = tf.constant([100, 200, 300])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((X, meta), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e762262a-be0b-4a0d-b8b1-9630416b887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=100>), <tf.Tensor: shape=(), dtype=int32, numpy=0>) \n",
      "\n",
      "((<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=200>), <tf.Tensor: shape=(), dtype=int32, numpy=1>) \n",
      "\n",
      "((<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 6], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=300>), <tf.Tensor: shape=(), dtype=int32, numpy=0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689c7df-71b9-472f-af7c-8204525816d7",
   "metadata": {},
   "source": [
    "## Chaining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ce5c3e-c772-4f65-a25e-c3a9166aeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset=dataset.repeat(3).batch(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd7d515-549f-4fa5-b5be-18b0e6712a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc7eced5-536f-45de-83b8-ef921a24ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.map(lambda x:x*2)   # x is a batch\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "220cdf00-a4b3-4fa1-8d46-51de40a47cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 13:44:32.193214: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.filter(lambda x:tf.reduce_sum(x)>50)  # x is a batch\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5937ac37-fbce-482b-9bae-ddd42cb9c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e0dc7f-93a3-47d2-87d3-52f6fa7f5008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 2\n",
      "Processing 7\n",
      "Processing 0\n",
      "Processing 3\n",
      "Processing 6\n",
      "0Processing 8\n",
      "\n",
      "Processing 9\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def slow_map_fn(x):\n",
    "    tf.print(\"Processing\", x)\n",
    "    time.sleep(1)  # simulate slow processing\n",
    "    return x * x\n",
    "\n",
    "dataset=tf.data.Dataset.range(10)\n",
    "dataset=dataset.map(lambda x: tf.py_function(slow_map_fn, [x], tf.int64)\n",
    "                      ,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "for item in dataset:\n",
    "    print(item.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23849cd5-90d9-4a2d-aac0-0a4ea7b0c392",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db4058f9-65b3-4664-b95b-06cc7fe7ac1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#This will shuffle batches\n",
    "dataset=tf.data.Dataset.range(10).repeat(2).batch(7)\n",
    "dataset=dataset.shuffle(buffer_size=4)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "822e0cc4-168d-4b42-9201-a5b869add36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 3  7  5  6  4  0 10], shape=(7,), dtype=int64)\n",
      "tf.Tensor([ 1  9  2 17 11 12 15], shape=(7,), dtype=int64)\n",
      "tf.Tensor([19 13  8 18 16 14], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#This Shuffles individual elements\n",
    "dataset=tf.data.Dataset.range(20)\n",
    "dataset=dataset.shuffle(buffer_size=10).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44580456-e5f4-48b2-88a8-e39bcf10ac88",
   "metadata": {},
   "source": [
    "## Interleaving lines from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f26388a-e9b5-4a4d-a5f7-d41e457cc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing=fetch_california_housing()\n",
    "X_train_full,X_test,y_train_full,y_test=train_test_split(housing.data,\n",
    "                                                         housing.target.reshape(-1,1),random_state=42)\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train_full,y_train_full,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c99a616b-049b-4072-937e-89e44872fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def save_to_csv_files(data,name_prefix,header=None,n_parts=10):\n",
    "    housing_dir=Path()/\"datasets\"/\"housing\"\n",
    "    housing_dir.mkdir(parents=True,exist_ok=True)\n",
    "    filename_format=\"my_{}_{:02d}.csv\"\n",
    "\n",
    "    filepaths=[]\n",
    "    m=len(data)\n",
    "    chunks=np.array_split(np.arange(m),n_parts)\n",
    "\n",
    "    for file_idx,row_indices in enumerate(chunks):\n",
    "        part_csv=housing_dir/filename_format.format(name_prefix,file_idx)\n",
    "        filepaths.append(str(part_csv))\n",
    "        with open(part_csv,\"w\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([str(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths\n",
    "\n",
    "train_data=np.c_[X_train,y_train]\n",
    "valid_data=np.c_[X_valid,y_valid]\n",
    "test_data=np.c_[X_test,y_test]\n",
    "header_cols=housing.feature_names+[\"MedianHouseValue\"]\n",
    "header=\",\".join(header_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74ce1529-9454-481f-b4c6-84d4dbb7c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths=save_to_csv_files(train_data,\"train\",header,n_parts=20)\n",
    "valid_filepaths=save_to_csv_files(valid_data,\"valid\",header,n_parts=10)\n",
    "test_filepaths=save_to_csv_files(test_data,\"test\",header,n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9f3931a-0f94-4ee9-a12f-cef8722b451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(open(train_filepaths[0]).readlines()[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02332a5f-e0dd-4553-931a-3e5e27c47c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/housing/my_train_00.csv',\n",
       " 'datasets/housing/my_train_01.csv',\n",
       " 'datasets/housing/my_train_02.csv',\n",
       " 'datasets/housing/my_train_03.csv',\n",
       " 'datasets/housing/my_train_04.csv',\n",
       " 'datasets/housing/my_train_05.csv',\n",
       " 'datasets/housing/my_train_06.csv',\n",
       " 'datasets/housing/my_train_07.csv',\n",
       " 'datasets/housing/my_train_08.csv',\n",
       " 'datasets/housing/my_train_09.csv',\n",
       " 'datasets/housing/my_train_10.csv',\n",
       " 'datasets/housing/my_train_11.csv',\n",
       " 'datasets/housing/my_train_12.csv',\n",
       " 'datasets/housing/my_train_13.csv',\n",
       " 'datasets/housing/my_train_14.csv',\n",
       " 'datasets/housing/my_train_15.csv',\n",
       " 'datasets/housing/my_train_16.csv',\n",
       " 'datasets/housing/my_train_17.csv',\n",
       " 'datasets/housing/my_train_18.csv',\n",
       " 'datasets/housing/my_train_19.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df034332-18a5-45ad-8ce3-9b0ad074d086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/housing/my_test_00.csv',\n",
       " 'datasets/housing/my_test_01.csv',\n",
       " 'datasets/housing/my_test_02.csv',\n",
       " 'datasets/housing/my_test_03.csv',\n",
       " 'datasets/housing/my_test_04.csv',\n",
       " 'datasets/housing/my_test_05.csv',\n",
       " 'datasets/housing/my_test_06.csv',\n",
       " 'datasets/housing/my_test_07.csv',\n",
       " 'datasets/housing/my_test_08.csv',\n",
       " 'datasets/housing/my_test_09.csv']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498947c3-841b-409e-af5c-424a566efcc2",
   "metadata": {},
   "source": [
    "#### Building an Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6a7aaf1-23ce-4b78-b70d-7fd3ed448e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dataset=tf.data.Dataset.list_files(train_filepaths,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0d931fc-0ccb-4e32-90e7-b7a3e963593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepath_dataset:\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc28c80a-6715-49e3-b4c0-db7b0f4e9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers=5\n",
    "dataset=filepath_dataset.interleave(\n",
    "    lambda filepath:tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03996f80-b406-4b41-92ee-42f92e834e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418', shape=(), dtype=string)\n",
      "tf.Tensor(b'2.4792,24.0,3.4547038327526134,1.1341463414634145,2251.0,3.921602787456446,34.18,-118.38,2.0', shape=(), dtype=string)\n",
      "tf.Tensor(b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67', shape=(), dtype=string)\n",
      "tf.Tensor(b'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(4):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7e892-4f06-4e43-8309-78e8d985dfaa",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7d83155-28b5-4e84-aa62-04113b681bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b12c2eb4-8499-412d-9c82-7c85f1943116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean,X_std=scaler.mean_,scaler.scale_\n",
    "n_inputs=8\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    defs=[0.]*n_inputs+[tf.constant([],dtype=tf.float32)]\n",
    "    fields=tf.io.decode_csv(line,record_defaults=defs)\n",
    "    return tf.stack(fields[:-1]),tf.stack(fields[-1:])\n",
    "\n",
    "def preprocess(line):\n",
    "    x,y=parse_csv_line(line)\n",
    "    return (x-X_mean)/X_std,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ac1a175-7602-4f39-ac08-5c66799d06b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([-0.19397889, -1.0778131 , -0.9433854 ,  0.01485314, -1.2998114 ,\n",
       "        -0.5729162 ,  0.9292612 , -1.4221538 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'3.5214,15.0,3.0499445061043287,1.106548279689234,,1.6059933407325193,37.63,-122.43,0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec31ce-dac5-43b4-a552-7acf48ec0214",
   "metadata": {},
   "source": [
    "## Putting Everything Together + Prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3518c78-ceb6-4593-a72f-18c900e77432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepath,n_readers=5,n_read_threads=None,n_parse_threads=4,\n",
    "                      shuffle_buffer_size=10000,seed=42,batch_size=32,repeat=False):\n",
    "    dataset=tf.data.Dataset.list_files(filepath,seed=seed)\n",
    "    dataset=dataset.interleave(\n",
    "        lambda filepath:tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers,num_parallel_calls=n_read_threads  )\n",
    "    dataset=dataset.map(preprocess,num_parallel_calls=n_parse_threads)\n",
    "    dataset=dataset.shuffle(buffer_size=shuffle_buffer_size,seed=seed)\n",
    "    if repeat:\n",
    "        dataset=dataset.repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec3e2615-c8ed-4d78-b810-090c2003fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[-1.3957452  -0.04940685 -0.22830808  0.22648273  2.2593622   0.35200632\n",
      "   0.9667386  -1.4121602 ]\n",
      " [ 2.7112627  -1.0778131   0.69413143 -0.14870553  0.51810503  0.3507294\n",
      "  -0.82285154  0.80680597]\n",
      " [-0.13484643 -1.868895    0.01032507 -0.13787179 -0.12893449  0.03143518\n",
      "   0.2687057   0.13212144]\n",
      " [ 0.09031774  0.9789995   0.1327582  -0.13753782 -0.23388447  0.10211545\n",
      "   0.97610843 -1.4121602 ]], shape=(4, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.819]\n",
      " [3.674]\n",
      " [0.954]\n",
      " [2.725]], shape=(4, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[ 0.05218809 -2.0271113   0.2940109  -0.02403445  0.16218767 -0.02844518\n",
      "   1.4117942  -0.93737936]\n",
      " [-0.672276    0.02970133 -0.76922584 -0.15086786  0.4962024  -0.02741998\n",
      "  -0.7853724   0.77182245]\n",
      " [-0.8111771   0.34613404 -0.21826383 -0.0801027   0.06636376  0.26724264\n",
      "   0.1937491   0.30204034]\n",
      " [-0.689403    1.8491895  -0.80511904 -0.08778115  1.0903106  -0.36003128\n",
      "   0.994848   -1.4171551 ]], shape=(4, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.205]\n",
      " [1.625]\n",
      " [0.474]\n",
      " [3.25 ]], shape=(4, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_set=csv_reader_dataset(train_filepaths,batch_size=4)\n",
    "for X_batch,y_batch in example_set.take(2):\n",
    "    print(\"X =\",X_batch)\n",
    "    print(\"y =\",y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a793ae-534c-4005-8e9e-bc7b54f46db2",
   "metadata": {},
   "source": [
    "## Using Dataset with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fbc291e-f5ff-42ed-bc93-956c7baf4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=csv_reader_dataset(train_filepaths,repeat=True)\n",
    "valid_set=csv_reader_dataset(valid_filepaths)\n",
    "test_set=csv_reader_dataset(test_filepaths,repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18daefba-f27a-4321-b2cd-7253e17c96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96dedbba-1301-4370-a5e3-1c6783524cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20,activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29775884-b73e-41b2-9d53-2c4d56dca206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - loss: 3.8101 - val_loss: 3.9114\n",
      "Epoch 2/3\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.9672 - val_loss: 0.8660\n",
      "Epoch 3/3\n",
      "\u001b[1m362/362\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.6777 - val_loss: 0.6843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1044fd580>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\",optimizer=\"nadam\")\n",
    "\n",
    "step_per_epoch=len(X_train)//32\n",
    "validation_steps=len(X_valid)//32\n",
    "model.fit(train_set,\n",
    "         epochs=3,\n",
    "         steps_per_epoch=step_per_epoch,\n",
    "         validation_data=valid_set,\n",
    "         validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03c50095-f6a3-486b-b195-c869abe62a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 0.5918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5716007947921753"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set,steps=len(X_test)//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3cb3bdb4-0580-4beb-b2bd-f04fd5640e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "new_set=test_set.take(2)\n",
    "y_pred=model.predict(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86dbdb-78e6-4836-b3a8-c82597d13122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 13:44:39.250567: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn=tf.keras.losses.MeanSquaredError()\n",
    "steps_per_epoch = len(X_train) // 32\n",
    "n_epochs=5\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    print(\"\\rEpoch: {}/{}\".format(epoch,n_epochs),end=\"\")\n",
    "    for X_batch,y_batch in train_set.take(steps_per_epoch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred=model(X_batch)\n",
    "            main_loss=tf.reduce_mean(loss_fn(y_batch,y_pred))\n",
    "            loss=tf.add_n([main_loss]+model.losses)\n",
    "\n",
    "        gradient=tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradient,model.trainable_variables))\n",
    "print(\"\\nTraining Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf31518-8e6d-4c7a-8272-363ec8335c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model,X_batch,y_batch,optimizer,loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        y_pred=model(X_batch)\n",
    "        main_loss=tf.reduce_mean(loss_fn(y_batch,y_pred))\n",
    "        loss=tf.add_n([main_loss]+model.losses)\n",
    "    gradient=tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient,model.trainable_variables))\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "steps_per_epoch=len(X_train)//32\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn=tf.keras.losses.MeanSquaredError()\n",
    "n_epochs=5\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    print(\"\\rEpoch: {}/{}\".format(epoch,n_epochs),end=\"\")\n",
    "    for X_batch,y_batch in train_set.take(steps_per_epoch):       \n",
    "        train_step(model,X_batch,y_batch,optimizer,loss_fn)\n",
    "print(\"\\nTraining Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d32431-6ad3-4303-9a3b-42df221eb6ff",
   "metadata": {},
   "source": [
    "# The TFRecord Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f7649-dc99-457f-a9e6-34670407cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record.\")\n",
    "    f.write(b\"This is just after first record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c5cb4-028d-421b-9eec-c6134375707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths=[\"my_data.tfrecord\"]\n",
    "\n",
    "dataset=tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d592d-83a1-49b8-9297-b3d02b0f9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepaths=[\"my_test_{}\".format(i) for i in range(5)]\n",
    "for i ,filepath in enumerate(filepaths):\n",
    "   with tf.io.TFRecordWriter(filepath) as f:\n",
    "       for j in range(3):\n",
    "           f.write(\"File: {} Record: {}\".format(i,j))\n",
    "\n",
    "dataset=tf.data.TFRecordDataset(filepaths,num_parallel_reads=3)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "       \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae872998-a214-4a41-a1a8-272d50c70eae",
   "metadata": {},
   "source": [
    "## Compressed TFRecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7668e-ad58-4b62-990b-c1deec7b0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "options=tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\",options) as f:\n",
    "    f.write(b\"Compress, compress, compress!\")\n",
    "dataset=tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],compression_type=\"GZIP\")\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be613715-584d-43f3-aad5-52fde753a344",
   "metadata": {},
   "source": [
    "## Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8039521-e787-49e2-9275-dc7d0c9820d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile person.proto\n",
    "syntax=\"proto3\";\n",
    "message Person{\n",
    "    string name=1;\n",
    "    int32 id=2;\n",
    "    repeated string email=3;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566e849-d6d9-4e13-983d-fca52dd12e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6fa896-ccc4-48b3-9364-38792a9561d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from person_pb2 import Person\n",
    "\n",
    "person=Person(name=\"AGI\",id=222,email=[\"abc@d.com\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70a0de-812c-4eac-a691-84ea4acb498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98aed6-eba2-48f7-bf2a-2d2bddc34f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9411e-2624-45f4-9b4c-4bc01355de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.name=\"ASI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e471dd-ac23-460b-adf1-2cf08e0d2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc00369-d5bb-42c3-a912-9354ca9a6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.email.append(\"dd@g.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04146853-87ff-4eed-9f71-6e4e9ddfa9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede10b1b-9964-47ba-9c3e-f0303b46c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized = person.SerializeToString()\n",
    "serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935be625-758d-47e7-98dd-aee3f932eb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person2=Person()\n",
    "person2.ParseFromString(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469f4be-01bb-4db9-827d-a588c4861b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "person2==person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150d9ac-e803-432e-abe3-df6266b2b3b4",
   "metadata": {},
   "source": [
    "#### Custom Protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661c072-891d-47d4-89ef-dc150c8c6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_tf=tf.io.decode_proto(\n",
    "    bytes=serialized,\n",
    "    message_type=\"Person\",\n",
    "    field_names=[\"name\",\"id\",\"email\"],\n",
    "    output_types=[tf.string,tf.int32,tf.string],\n",
    "    descriptor_source=\"person.desc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f71090-79f1-4f9b-ba23-f434487f430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_tf.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddad41f-c7ad-4e43-a7cc-a15413abde4b",
   "metadata": {},
   "source": [
    "### TensorFlow Protobufs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524db0e-eb7c-409d-be03-995fec094f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList,FloatList,Int64List\n",
    "from tensorflow.train import Feature,Example,Features\n",
    "\n",
    "person_example=Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\":Feature(bytes_list=BytesList(value=[b\"AGI\"])),\n",
    "            \"id\":Feature(int64_list=Int64List(value=[123])),\n",
    "            \"email\":Feature(bytes_list=BytesList(value=[b\"a@b.com\",\n",
    "                                                        b\"c@d.com\"]))\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b1de6-4342-4fe4-9858-50787022c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    for _ in range(5):\n",
    "        f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a8050-2f73-4de4-b9f2-cc2514b0123b",
   "metadata": {},
   "source": [
    "### Loading and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5aa3e-c7b0-43c0-b83d-ea9405f7f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description={\n",
    "    \"name\": tf.io.FixedLenFeature([],tf.string,default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([],tf.int64,default_value=0),\n",
    "    \"email\": tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "def parse(serialized_example):\n",
    "    return tf.io.parse_single_example(serialized_example,feature_description)\n",
    "\n",
    "dataset=tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).map(parse)\n",
    "\n",
    "for record in dataset:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5bf83-ac00-42f5-8d2a-51791eb1841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sparse.to_dense(record[\"email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460aaf3-42bb-45fb-9a35-ecbf65024ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "record[\"email\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a5f53-25a2-4a2c-8428-ed3cf57b5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(serialized_example):\n",
    "    return tf.io.parse_example(serialized_example,feature_description)\n",
    "\n",
    "dataset=tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(2).map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c876dc-ec9c-4829-89af-0e2d12c9a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in dataset:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e08bf2-a8ac-4451-9612-cd954f92755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab308e-167a-4079-9fa4-b936123973b6",
   "metadata": {},
   "source": [
    "###  Convert CSV → TFRecord → Load TFRecord and Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cd3d3-aa48-4488-a384-e15dc2d94e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample csv\n",
    "import csv \n",
    "rows = [\n",
    "    [\"name\", \"age\", \"weight\"],\n",
    "    [\"Alice\", 25, 55.5],\n",
    "    [\"Bob\", 30, 72.3],\n",
    "    [\"Charlie\", 22, 60.0]\n",
    "]\n",
    "\n",
    "with open(\"people.csv\",\"w\",newline=\"\") as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1c5a5-6a32-4b37-95b8-75d73249c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert CSV to TFRecord\n",
    "def new_person_example(name,age,weight):\n",
    "    return Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\":Feature(bytes_list=BytesList(value=[name.encode()])),\n",
    "            \"age\":Feature(int64_list=Int64List(value=[age])),\n",
    "            \"weight\":Feature(float_list=FloatList(value=[weight]))\n",
    "            \n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "with open(\"people.csv\") as f,tf.io.TFRecordWriter(\"people.tfrecord\") as writer:\n",
    "    next(f) #skip header\n",
    "    for line in f:\n",
    "        name,age,weight=line.strip().split(\",\")\n",
    "        example=new_person_example(name,int(age),float(weight))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed03ad3-4165-4409-b8c6-4bcb65d8fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Parse TFRecord\n",
    "feature_description={\n",
    "    \"name\":tf.io.FixedLenFeature([],tf.string),\n",
    "    \"age\":tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"weight\":tf.io.FixedLenFeature([],tf.float32)\n",
    "}\n",
    "\n",
    "def parse(serialized_example):\n",
    "    return tf.io.parse_single_example(serialized_example,feature_description)\n",
    "\n",
    "dataset=tf.data.TFRecordDataset([\"people.tfrecord\"])\n",
    "dataset=dataset.map(parse)\n",
    "\n",
    "for record in dataset:\n",
    "    print(\"Name:\",record[\"name\"].numpy().decode())\n",
    "    print(\"Age:\",record[\"age\"].numpy())\n",
    "    print(\"Weight:\",record[\"weight\"].numpy())\n",
    "    print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4690e83-30b6-4e90-bdb2-cece26618fd4",
   "metadata": {},
   "source": [
    "## Storing Images and Tensors in TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d56190-d739-4ce4-9c15-e0e853b57d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "image=load_sample_images()[\"images\"][1]\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87194d-7b72-404b-80fd-03bf51d6da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf51ef-d1a6-4357-95f0-f3c92a108615",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tf.io.encode_jpeg(image).numpy()\n",
    "\n",
    "example_with_image=Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"image\":Feature(bytes_list=BytesList(value=[data]))\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "serialized_example=example_with_image.SerializeToString()\n",
    "with tf.io.TFRecordWriter(\"my_image.tfrecord\") as f:\n",
    "    f.write(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ea062-7a79-450c-a280-bf24ff7a051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description={\n",
    "    \"image\":tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "def parse(serialized_example):\n",
    "    example_with_image=tf.io.parse_single_example(serialized_example,feature_description)\n",
    "    return tf.io.decode_jpeg(example_with_image[\"image\"].values[0])\n",
    "\n",
    "\n",
    "dataset=tf.data.TFRecordDataset(\"my_image.tfrecord\").map(parse)\n",
    "\n",
    "for image in dataset:  \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf078e-19ee-45ac-ac3e-e493741b9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return Feature(bytes_list=BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return Feature(int64_list=Int64List(value=[value]))\n",
    "\n",
    "def image_example(image_string,label):\n",
    "    feature={\n",
    "        \"image\":_bytes_feature(image_string),\n",
    "        \"label\":_int64_feature(label)\n",
    "    }\n",
    "    return Example(features=Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98069e-5ecc-45c9-94de-7348f3c4b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=\"images\"\n",
    "tfrecord_file=\"images.tfrecord\"\n",
    "\n",
    "with tf.io.TFRecordWriter(tfrecord_file)as writer:\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            path=os.path.join(image_dir,filename)\n",
    "            label= 0 if \"cat\" in filename else 1\n",
    "\n",
    "\n",
    "            img_raw=tf.io.read_file(path).numpy()\n",
    "            example=image_example(img_raw,label)\n",
    "            writer.write(example.SerializeToString())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942106bd-a78b-4a97-8214-a8f07f5c1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description={\n",
    "    \"image\":tf.io.FixedLenFeature([],tf.string),\n",
    "    \"label\":tf.io.FixedLenFeature([],tf.int64)\n",
    "}\n",
    "\n",
    "def parse(serialized_example):\n",
    "    parsed=tf.io.parse_single_example(serialized_example,feature_description)\n",
    "    img=tf.io.decode_image(parsed[\"image\"],channels=3)\n",
    "    label=parsed[\"label\"]\n",
    "    return img,label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d315373-4c65-4c1a-9603-e34beacf9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.TFRecordDataset([\"images.tfrecord\"]).map(parse)\n",
    "\n",
    "for idx,(img,label) in enumerate(dataset):\n",
    "    plt.subplot(2,2,idx+1)\n",
    "    plt.imshow(img.numpy())\n",
    "    plt.title(f\"Label:{\"Cat\"if label==0 else \"Dog\"}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
